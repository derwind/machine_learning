{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12890ee1",
   "metadata": {},
   "source": [
    "# Titanic problem\n",
    "\n",
    "## Use LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b88ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93432c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e62340e-67fb-469f-b869-f8b814ef163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_surname(item):\n",
    "    return item['Name'].split(',')[0]\n",
    "\n",
    "def get_n_members(item):\n",
    "    return (item['SibSp']+item['Parch'] +\n",
    "           1) # self\n",
    "\n",
    "def get_passengers_ticket_numbers(passengers):\n",
    "    tickets = {p['Ticket'] for p in passengers}\n",
    "    if len(tickets) <= 1:\n",
    "        return tickets.pop()\n",
    "    else:\n",
    "        return tickets\n",
    "\n",
    "# Holders of close ticket numbers are likely to be family members.\n",
    "def family_like(item, fam_members):\n",
    "    ticket = item['Ticket']\n",
    "    for member in fam_members:\n",
    "        mem_ticket = member['Ticket']\n",
    "        if ticket == mem_ticket:\n",
    "            return True\n",
    "        if ticket.isdigit() and mem_ticket.isdigit() and abs(int(ticket) - int(mem_ticket)) <= 2:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def group_families(df):\n",
    "    families = {}\n",
    "\n",
    "    for i, (column_name, item) in enumerate(df.iterrows()):\n",
    "        fam_name = get_surname(item)\n",
    "        ticket_num = item['Ticket']\n",
    "        fam_dict = families.setdefault(fam_name, {})\n",
    "        for cnt in range(100):\n",
    "            fam_name_mod = f'{fam_name}#{cnt}'\n",
    "            if fam_name_mod in fam_dict:\n",
    "                if family_like(item, fam_dict[fam_name_mod]):\n",
    "                    fam_dict[fam_name_mod].append(item)\n",
    "                    break\n",
    "            else:\n",
    "                fam_dict.setdefault(fam_name_mod, []).append(item)\n",
    "                break\n",
    "    return families\n",
    "\n",
    "def split_single_family_passengers(df, families):\n",
    "    single_indices = set()\n",
    "    family_indices = set()\n",
    "    for fam_name, subfamilies in families.items():\n",
    "        for _, passengers in subfamilies.items():\n",
    "            if len(passengers) <= 1:\n",
    "                single_indices.add(passengers[0]['PassengerId'])\n",
    "            else:\n",
    "                for p in passengers:\n",
    "                    family_indices.add(p['PassengerId'])\n",
    "    return df[df['PassengerId'].isin(sorted(single_indices))], df[df['PassengerId'].isin(sorted(family_indices))]\n",
    "\n",
    "families = group_families(train_df)\n",
    "single_df, family_df = split_single_family_passengers(train_df, families)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31da893d",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3ddf891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    # This makes df['Sex'] viewing instead of copying...?\n",
    "    df = pd.DataFrame(df)\n",
    "    df = df.dropna(subset=['Age'])\n",
    "    df['Sex'].replace(['male', 'female'], [0, 1], inplace=True)\n",
    "    df = pd.get_dummies(df, columns=['Embarked'])\n",
    "\n",
    "    X_df = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']]\n",
    "    y_df = df[['Survived']]\n",
    "    X_keys = list(X_df.keys())\n",
    "    X_values = X_df.values\n",
    "    y_values = np.squeeze(y_df.values)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_values, y_values, test_size=0.3, random_state=1, stratify=y_values)\n",
    "    return X_train, X_test, y_train, y_test, X_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9b990",
   "metadata": {},
   "source": [
    "## Use LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60479082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob2index(prob):\n",
    "    return np.array([np.argmax(ps) for ps in prob])\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    params = {\n",
    "        'objective':'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': 2,\n",
    "        'max_depth': 3,\n",
    "        'eta': 0.1,\n",
    "        'verbosity': 0,\n",
    "        'random_state': 71,\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        'objective':'multiclass',\n",
    "        'metric': 'multi_logloss',\n",
    "        'num_class': 2,\n",
    "        'max_depth': 3,\n",
    "        'learning_rate': 0.1,\n",
    "        'verbosity': -1,\n",
    "        'early_stopping_round': 10,\n",
    "    }\n",
    "    \n",
    "    accs = []\n",
    "    models = []\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    for fold_id, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "        X_tr  = X_train[train_idx, :]\n",
    "        X_val = X_train[val_idx, :]\n",
    "        y_tr  = y_train[train_idx]\n",
    "        y_val = y_train[val_idx]\n",
    "        dtrain = lgb.Dataset(X_tr, label=y_tr)\n",
    "        dvalid = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "        callbacks = [\n",
    "            lgb.log_evaluation(0),\n",
    "            lgb.early_stopping(10),\n",
    "        ]\n",
    "        gbm = lgb.train(params, dtrain, num_boost_round=10, valid_sets=dvalid, callbacks=callbacks)\n",
    "        y_pred = prob2index(gbm.predict(X_val))\n",
    "        conf_mat = confusion_matrix(y_val, y_pred)\n",
    "        val_acc = np.trace(conf_mat) / len(y_val)\n",
    "        accs.append(val_acc)\n",
    "        models.append(gbm)\n",
    "        print(f'[{fold_id}] val acc={val_acc}')\n",
    "\n",
    "    best_idx = np.argmax(accs)\n",
    "    best_model = models[best_idx]\n",
    "    print(f'{best_idx=}')\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80aa8d1-c59b-4194-ac35-714523eea6c1",
   "metadata": {},
   "source": [
    "## Train and evaluation for single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bdadb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[0] val acc=0.8235294117647058\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[1] val acc=0.7761194029850746\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's multi_logloss: 0.521598\n",
      "[2] val acc=0.746268656716418\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[3] val acc=0.835820895522388\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[4] val acc=0.8507462686567164\n",
      "best_idx=4\n",
      "[[84  6]\n",
      " [27 28]]\n",
      "acc: 0.7724137931034483\n"
     ]
    }
   ],
   "source": [
    "X_train_s, X_test_s, y_train_s, y_test_s, _ = prepare_data(single_df)\n",
    "model = train_model(X_train_s, y_train_s)\n",
    "y_pred = prob2index(model.predict(X_test_s))\n",
    "conf_mat = confusion_matrix(y_test_s, y_pred)\n",
    "print(conf_mat)\n",
    "print('acc:', np.trace(conf_mat) / len(y_test_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c26ee75-35ea-4710-b942-9372b81836cd",
   "metadata": {},
   "source": [
    "## Train and evaluation for family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb9be9e-febc-4d15-974f-dfcba0a3c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[0] val acc=0.7575757575757576\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[1] val acc=0.7272727272727273\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2] val acc=0.8181818181818182\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[3] val acc=0.84375\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[4] val acc=0.6875\n",
      "best_idx=3\n",
      "[[35  2]\n",
      " [ 8 25]]\n",
      "acc: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "X_train_f, X_test_f, y_train_f, y_test_f, _ = prepare_data(family_df)\n",
    "model = train_model(X_train_f, y_train_f)\n",
    "y_pred = prob2index(model.predict(X_test_f))\n",
    "conf_mat = confusion_matrix(y_test_f, y_pred)\n",
    "print(conf_mat)\n",
    "print('acc:', np.trace(conf_mat) / len(y_test_f))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
