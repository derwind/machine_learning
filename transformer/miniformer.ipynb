{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JglVEQU1_-zP",
    "outputId": "f782b199-d8fa-4a0b-e0f6-69fb9bf7e0f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/157.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.5/157.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/139.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -qU bertviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ooIMhUHo-2sa"
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import random\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGBQ9NqHogJ0"
   },
   "outputs": [],
   "source": [
    "ANIMALS = [\n",
    "  \"cat\",\n",
    "  \"caracal\",\n",
    "  \"capybara\",\n",
    "  \"canary\",\n",
    "  \"cavy\",\n",
    "  \"caiman\",\n",
    "  \"cacomistle\",\n",
    "  \"caribou\",\n",
    "  \"cassowary\",\n",
    "  \"caterpillar\",\n",
    "  \"dog\",\n",
    "  \"dalmatian\",\n",
    "  \"dachshund\",\n",
    "  \"doberman\",\n",
    "  \"duck\",\n",
    "  \"dingo\",\n",
    "  \"lion\",\n",
    "  \"tiger\",\n",
    "  \"leopard\",\n",
    "  \"cheetah\",\n",
    "  \"puma\",\n",
    "  \"jaguar\",\n",
    "  \"lynx\",\n",
    "  \"ocelot\",\n",
    "  \"serval\",\n",
    "  \"bobcat\",\n",
    "  \"cougar\",\n",
    "  \"panther\",\n",
    "  \"wolf\",\n",
    "  \"fox\",\n",
    "  \"jackal\",\n",
    "  \"coyote\",\n",
    "  \"hyena\",\n",
    "  \"bear\",\n",
    "  \"polar\",\n",
    "  \"grizzly\",\n",
    "  \"slothbear\",\n",
    "  \"panda\",\n",
    "  \"koala\",\n",
    "  \"kangaroo\",\n",
    "  \"wallaby\",\n",
    "  \"opossum\",\n",
    "  \"wombat\",\n",
    "  \"tasmanian\",\n",
    "  \"rabbit\",\n",
    "  \"hare\",\n",
    "  \"mouse\",\n",
    "  \"rat\",\n",
    "  \"gerbil\",\n",
    "  \"hamster\",\n",
    "  \"guinea\",\n",
    "  \"squirrel\",\n",
    "  \"chipmunk\",\n",
    "  \"beaver\",\n",
    "  \"porcupine\",\n",
    "  \"hedgehog\",\n",
    "  \"shrew\",\n",
    "  \"mole\",\n",
    "  \"bat\",\n",
    "  \"armadillo\",\n",
    "  \"antelope\",\n",
    "  \"gazelle\",\n",
    "  \"impala\",\n",
    "  \"gnu\",\n",
    "  \"eland\",\n",
    "  \"springbok\",\n",
    "  \"deer\",\n",
    "  \"moose\",\n",
    "  \"elk\",\n",
    "  \"reindeer\",\n",
    "  \"stag\",\n",
    "  \"doe\",\n",
    "  \"fawn\",\n",
    "  \"buffalo\",\n",
    "  \"bison\",\n",
    "  \"yak\",\n",
    "  \"zebu\",\n",
    "  \"cow\",\n",
    "  \"bull\",\n",
    "  \"ox\",\n",
    "  \"calf\",\n",
    "  \"sheep\",\n",
    "  \"lamb\",\n",
    "  \"ram\",\n",
    "  \"goat\",\n",
    "  \"kid\",\n",
    "  \"ibex\",\n",
    "  \"chamois\",\n",
    "  \"camel\",\n",
    "  \"dromedary\",\n",
    "  \"llama\",\n",
    "  \"alpaca\",\n",
    "  \"vicuna\",\n",
    "  \"horse\",\n",
    "  \"mare\",\n",
    "  \"stallion\",\n",
    "  \"colt\",\n",
    "  \"foal\",\n",
    "  \"donkey\",\n",
    "  \"mule\",\n",
    "  \"zebra\",\n",
    "  \"rhinoceros\",\n",
    "  \"hippopotamus\",\n",
    "  \"pig\",\n",
    "  \"boar\",\n",
    "  \"hog\",\n",
    "  \"swine\",\n",
    "  \"babirusa\",\n",
    "  \"tapir\",\n",
    "  \"elephant\",\n",
    "  \"mammoth\",\n",
    "  \"mastodon\",\n",
    "  \"dugong\",\n",
    "  \"manatee\",\n",
    "  \"whale\",\n",
    "  \"dolphin\",\n",
    "  \"porpoise\",\n",
    "  \"seal\",\n",
    "  \"seaotter\",\n",
    "  \"walrus\",\n",
    "  \"otter\",\n",
    "  \"weasel\",\n",
    "  \"ferret\",\n",
    "  \"marten\",\n",
    "  \"ermine\",\n",
    "  \"badger\",\n",
    "  \"skunk\",\n",
    "  \"wolverine\",\n",
    "  \"mongoose\",\n",
    "  \"meerkat\",\n",
    "  \"civet\",\n",
    "  \"genet\",\n",
    "  \"fossa\",\n",
    "  \"bearcat\",\n",
    "  \"platypus\",\n",
    "  \"echidna\",\n",
    "  \"pangolin\",\n",
    "  \"aardvark\",\n",
    "  \"aardwolf\",\n",
    "  \"okapi\",\n",
    "  \"giraffe\",\n",
    "  \"monkey\",\n",
    "  \"baboon\",\n",
    "  \"mandrill\",\n",
    "  \"macaque\",\n",
    "  \"langur\",\n",
    "  \"gibbon\",\n",
    "  \"gorilla\",\n",
    "  \"chimpanzee\",\n",
    "  \"bonobo\",\n",
    "  \"orangutan\",\n",
    "  \"lemur\",\n",
    "  \"tarsier\",\n",
    "  \"loris\",\n",
    "  \"ayeaye\",\n",
    "  \"sloth\",\n",
    "  \"anteater\",\n",
    "  \"tamandua\",\n",
    "  \"kitten\",\n",
    "  \"puppy\",\n",
    "  \"duckling\",\n",
    "  \"gosling\",\n",
    "  \"cygnet\",\n",
    "  \"eagle\",\n",
    "  \"hawk\",\n",
    "  \"falcon\",\n",
    "  \"osprey\",\n",
    "  \"vulture\",\n",
    "  \"buzzard\",\n",
    "  \"kite\",\n",
    "  \"owl\",\n",
    "  \"barnowl\",\n",
    "  \"tawnyowl\",\n",
    "  \"screechowl\",\n",
    "  \"snowyowl\",\n",
    "  \"parrot\",\n",
    "  \"macaw\",\n",
    "  \"cockatoo\",\n",
    "  \"budgerigar\",\n",
    "  \"lovebird\",\n",
    "  \"lorikeet\",\n",
    "  \"conure\",\n",
    "  \"parakeet\",\n",
    "  \"kingfisher\",\n",
    "  \"woodpecker\",\n",
    "  \"toucan\",\n",
    "  \"hornbill\",\n",
    "  \"cuckoo\",\n",
    "  \"cuckooshrike\",\n",
    "  \"nightjar\",\n",
    "  \"swift\",\n",
    "  \"hummingbird\",\n",
    "  \"swallow\",\n",
    "  \"martin\",\n",
    "  \"wren\",\n",
    "  \"warbler\",\n",
    "  \"thrush\",\n",
    "  \"blackbird\",\n",
    "  \"starling\",\n",
    "  \"mockingbird\",\n",
    "  \"finch\",\n",
    "  \"canary\",\n",
    "  \"sparrow\",\n",
    "  \"bunting\",\n",
    "  \"lark\",\n",
    "  \"pipit\",\n",
    "  \"wagtail\",\n",
    "  \"robin\",\n",
    "  \"chat\",\n",
    "  \"wheatear\",\n",
    "  \"dipper\",\n",
    "  \"nuthatch\",\n",
    "  \"treecreeper\",\n",
    "  \"tit\",\n",
    "  \"chickadee\",\n",
    "  \"jay\",\n",
    "  \"magpie\",\n",
    "  \"crow\",\n",
    "  \"raven\",\n",
    "  \"rook\",\n",
    "  \"jackdaw\",\n",
    "  \"chough\",\n",
    "  \"shrike\",\n",
    "  \"oriole\",\n",
    "  \"drongo\",\n",
    "  \"bulbul\",\n",
    "  \"mina\",\n",
    "  \"weaver\",\n",
    "  \"whydah\",\n",
    "  \"waxbill\",\n",
    "  \"munia\",\n",
    "  \"manakin\",\n",
    "  \"cotinga\",\n",
    "  \"antbird\",\n",
    "  \"ovenbird\",\n",
    "  \"woodcreeper\",\n",
    "  \"flycatcher\",\n",
    "  \"tyrant\",\n",
    "  \"pewee\",\n",
    "  \"kingbird\",\n",
    "  \"boatbill\",\n",
    "  \"motmot\",\n",
    "  \"tody\",\n",
    "  \"jacamar\",\n",
    "  \"puffbird\",\n",
    "  \"barbet\",\n",
    "  \"toucanet\",\n",
    "  \"ani\",\n",
    "  \"turaco\",\n",
    "  \"hoatzin\",\n",
    "  \"bustard\",\n",
    "  \"crane\",\n",
    "  \"heron\",\n",
    "  \"egret\",\n",
    "  \"bittern\",\n",
    "  \"stork\",\n",
    "  \"ibis\",\n",
    "  \"spoonbill\",\n",
    "  \"flamingo\",\n",
    "  \"swan\",\n",
    "  \"goose\",\n",
    "  \"teal\",\n",
    "  \"wigeon\",\n",
    "  \"shoveler\",\n",
    "  \"pintail\",\n",
    "  \"scaup\",\n",
    "  \"pochard\",\n",
    "  \"canvasback\",\n",
    "  \"redhead\",\n",
    "  \"goldeneye\",\n",
    "  \"merganser\",\n",
    "  \"eider\",\n",
    "  \"scoter\",\n",
    "  \"shelduck\",\n",
    "  \"woodduck\",\n",
    "  \"mandarin\",\n",
    "  \"mallard\",\n",
    "  \"gadwall\",\n",
    "  \"grebe\",\n",
    "  \"loon\",\n",
    "  \"penguin\",\n",
    "  \"albatross\",\n",
    "  \"petrel\",\n",
    "  \"shearwater\",\n",
    "  \"prion\",\n",
    "  \"stormpetrel\",\n",
    "  \"fulmar\",\n",
    "  \"gannet\",\n",
    "  \"booby\",\n",
    "  \"cormorant\",\n",
    "  \"shag\",\n",
    "  \"anhinga\",\n",
    "  \"frigatebird\",\n",
    "  \"tropicbird\",\n",
    "  \"pelican\",\n",
    "  \"darter\",\n",
    "  \"gull\",\n",
    "  \"tern\",\n",
    "  \"skimmer\",\n",
    "  \"auk\",\n",
    "  \"murre\",\n",
    "  \"puffin\",\n",
    "  \"guillemot\",\n",
    "  \"razorbill\",\n",
    "  \"dovekie\",\n",
    "  \"murrelet\",\n",
    "  \"kiwi\",\n",
    "  \"emu\",\n",
    "  \"rhea\",\n",
    "  \"ostrich\",\n",
    "  \"tinamou\",\n",
    "  \"rail\",\n",
    "  \"crake\",\n",
    "  \"gallinule\",\n",
    "  \"coot\",\n",
    "  \"limpkin\",\n",
    "  \"buttonquail\",\n",
    "  \"plover\",\n",
    "  \"lapwing\",\n",
    "  \"dotterel\",\n",
    "  \"killdeer\",\n",
    "  \"oystercatcher\",\n",
    "  \"avocet\",\n",
    "  \"stilt\",\n",
    "  \"phalarope\",\n",
    "  \"jacana\",\n",
    "  \"sandpiper\",\n",
    "  \"snipe\",\n",
    "  \"curlew\",\n",
    "  \"godwit\",\n",
    "  \"dowitcher\",\n",
    "  \"stint\",\n",
    "  \"ruff\",\n",
    "  \"turnstone\",\n",
    "  \"knot\",\n",
    "  \"pratincole\",\n",
    "  \"courser\",\n",
    "  \"skua\",\n",
    "  \"jaeger\",\n",
    "  \"eel\",\n",
    "  \"salmon\",\n",
    "  \"trout\",\n",
    "  \"carp\",\n",
    "  \"catfish\",\n",
    "  \"cobia\",\n",
    "  \"cod\",\n",
    "  \"coelacanth\",\n",
    "  \"flounder\",\n",
    "  \"goby\",\n",
    "  \"grouper\",\n",
    "  \"guppy\",\n",
    "  \"haddock\",\n",
    "  \"hake\",\n",
    "  \"halibut\",\n",
    "  \"koi\",\n",
    "  \"mackerel\",\n",
    "  \"minnow\",\n",
    "  \"perch\",\n",
    "  \"pike\",\n",
    "  \"pollock\",\n",
    "  \"sardine\",\n",
    "  \"shad\",\n",
    "  \"smelt\",\n",
    "  \"snapper\",\n",
    "  \"sole\",\n",
    "  \"sturgeon\",\n",
    "  \"tilapia\",\n",
    "  \"tuna\",\n",
    "  \"wahoo\",\n",
    "  \"zander\",\n",
    "  \"anchovy\",\n",
    "  \"barracuda\",\n",
    "  \"bass\",\n",
    "  \"blenny\",\n",
    "  \"bluegill\",\n",
    "  \"bonito\",\n",
    "  \"bream\",\n",
    "  \"butterfish\",\n",
    "  \"capelin\",\n",
    "  \"char\",\n",
    "  \"clownfish\",\n",
    "  \"drum\",\n",
    "  \"grunion\",\n",
    "  \"herring\",\n",
    "  \"killifish\",\n",
    "  \"lamprey\",\n",
    "  \"lionfish\",\n",
    "  \"loach\",\n",
    "  \"molly\",\n",
    "  \"mudskipper\",\n",
    "  \"needlefish\",\n",
    "  \"parrotfish\",\n",
    "  \"pompano\",\n",
    "  \"scad\",\n",
    "  \"sculpin\",\n",
    "  \"seahorse\",\n",
    "  \"shark\",\n",
    "  \"skate\",\n",
    "  \"sprat\",\n",
    "  \"sucker\",\n",
    "  \"sunfish\",\n",
    "  \"surgeonfish\",\n",
    "  \"tarpon\",\n",
    "  \"tetra\",\n",
    "  \"trevally\",\n",
    "  \"triggerfish\",\n",
    "  \"wrasse\",\n",
    "  \"tang\",\n",
    "  \"abalone\",\n",
    "  \"barnacle\",\n",
    "  \"clam\",\n",
    "  \"cockle\",\n",
    "  \"conch\",\n",
    "  \"crab\",\n",
    "  \"crawfish\",\n",
    "  \"krill\",\n",
    "  \"limpet\",\n",
    "  \"lobster\",\n",
    "  \"mussel\",\n",
    "  \"nautilus\",\n",
    "  \"oyster\",\n",
    "  \"periwinkle\",\n",
    "  \"prawn\",\n",
    "  \"scallop\",\n",
    "  \"shrimp\",\n",
    "  \"snail\",\n",
    "  \"squid\",\n",
    "  \"octopus\",\n",
    "  \"urchin\",\n",
    "  \"worm\",\n",
    "  \"beetle\",\n",
    "  \"butterfly\",\n",
    "  \"caterpillar\",\n",
    "  \"dragonfly\",\n",
    "  \"earwig\",\n",
    "  \"firefly\",\n",
    "  \"flea\",\n",
    "  \"grasshopper\",\n",
    "  \"ladybug\",\n",
    "  \"mantis\",\n",
    "  \"moth\",\n",
    "  \"termite\",\n",
    "  \"tick\",\n",
    "  \"wasp\",\n",
    "  \"weevil\",\n",
    "  \"aphid\",\n",
    "  \"ant\",\n",
    "  \"bee\",\n",
    "  \"bug\",\n",
    "  \"cricket\",\n",
    "  \"damselfly\",\n",
    "  \"fly\",\n",
    "  \"gnat\",\n",
    "  \"hornet\",\n",
    "  \"mayfly\",\n",
    "  \"mosquito\",\n",
    "  \"silverfish\",\n",
    "  \"spider\",\n",
    "  \"centipede\",\n",
    "  \"millipede\",\n",
    "  \"scorpion\",\n",
    "  \"copepod\",\n",
    "  \"isopod\",\n",
    "  \"amphipod\",\n",
    "  \"woodlouse\",\n",
    "  \"horseshoecrab\",\n",
    "  \"arachnid\",\n",
    "  \"mite\",\n",
    "  \"tarantula\",\n",
    "  \"fruitfly\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCzkiEM_okPb"
   },
   "outputs": [],
   "source": [
    "FRUITS_VEGGIES = [\n",
    "  \"apple\",\n",
    "  \"apricot\",\n",
    "  \"avocado\",\n",
    "  \"artichoke\",\n",
    "  \"banana\",\n",
    "  \"bilberry\",\n",
    "  \"blackberry\",\n",
    "  \"blueberry\",\n",
    "  \"boysenberry\",\n",
    "  \"breadfruit\",\n",
    "  \"cantaloupe\",\n",
    "  \"casaba\",\n",
    "  \"carambola\",\n",
    "  \"cherimoya\",\n",
    "  \"cherry\",\n",
    "  \"cloudberry\",\n",
    "  \"coconut\",\n",
    "  \"cranberry\",\n",
    "  \"currant\",\n",
    "  \"date\",\n",
    "  \"elderberry\",\n",
    "  \"fig\",\n",
    "  \"gooseberry\",\n",
    "  \"grape\",\n",
    "  \"grapefruit\",\n",
    "  \"guava\",\n",
    "  \"honeydew\",\n",
    "  \"jackfruit\",\n",
    "  \"jambul\",\n",
    "  \"jujube\",\n",
    "  \"kiwi\",\n",
    "  \"kumquat\",\n",
    "  \"lemon\",\n",
    "  \"lime\",\n",
    "  \"loquat\",\n",
    "  \"lychee\",\n",
    "  \"mandarin\",\n",
    "  \"mango\",\n",
    "  \"mangosteen\",\n",
    "  \"melon\",\n",
    "  \"mulberry\",\n",
    "  \"nectarine\",\n",
    "  \"olive\",\n",
    "  \"orange\",\n",
    "  \"papaya\",\n",
    "  \"passionfruit\",\n",
    "  \"peach\",\n",
    "  \"pear\",\n",
    "  \"persimmon\",\n",
    "  \"pineapple\",\n",
    "  \"plum\",\n",
    "  \"pomegranate\",\n",
    "  \"pomelo\",\n",
    "  \"quince\",\n",
    "  \"raspberry\",\n",
    "  \"redcurrant\",\n",
    "  \"salak\",\n",
    "  \"satsuma\",\n",
    "  \"starfruit\",\n",
    "  \"strawberry\",\n",
    "  \"tamarillo\",\n",
    "  \"tamarind\",\n",
    "  \"tangelo\",\n",
    "  \"ugli\",\n",
    "  \"watermelon\",\n",
    "  \"yuzu\",\n",
    "  \"zucchini\",\n",
    "  \"carrot\",\n",
    "  \"cabbage\",\n",
    "  \"cauliflower\",\n",
    "  \"cassava\",\n",
    "  \"celery\",\n",
    "  \"chard\",\n",
    "  \"chicory\",\n",
    "  \"collard\",\n",
    "  \"corn\",\n",
    "  \"cress\",\n",
    "  \"cucumber\",\n",
    "  \"daikon\",\n",
    "  \"edamame\",\n",
    "  \"eggplant\",\n",
    "  \"endive\",\n",
    "  \"fennel\",\n",
    "  \"garlic\",\n",
    "  \"ginger\",\n",
    "  \"horseradish\",\n",
    "  \"jicama\",\n",
    "  \"kale\",\n",
    "  \"kohlrabi\",\n",
    "  \"leek\",\n",
    "  \"lettuce\",\n",
    "  \"okra\",\n",
    "  \"onion\",\n",
    "  \"parsnip\",\n",
    "  \"pea\",\n",
    "  \"pepper\",\n",
    "  \"potato\",\n",
    "  \"pumpkin\",\n",
    "  \"radish\",\n",
    "  \"rutabaga\",\n",
    "  \"shallot\",\n",
    "  \"spinach\",\n",
    "  \"squash\",\n",
    "  \"sweetcorn\",\n",
    "  \"sweetpotato\",\n",
    "  \"tomato\",\n",
    "  \"turnip\",\n",
    "  \"wasabi\",\n",
    "  \"yam\",\n",
    "  \"macadamia\",\n",
    "  \"pecan\",\n",
    "  \"cashew\",\n",
    "  \"hazelnut\",\n",
    "  \"walnut\",\n",
    "  \"almond\",\n",
    "  \"brazilnut\",\n",
    "  \"chestnut\",\n",
    "  \"pistachio\",\n",
    "  \"pine\",\n",
    "  \"acorn\",\n",
    "  \"watercress\",\n",
    "  \"caper\",\n",
    "  \"cardoon\",\n",
    "  \"canna\",\n",
    "  \"caraway\",\n",
    "  \"carob\",\n",
    "  \"camu\",\n",
    "  \"camote\",\n",
    "  \"canistel\",\n",
    "  \"canola\",\n",
    "  \"capers\",\n",
    "  \"carissa\",\n",
    "  \"catjang\",\n",
    "  \"cavendish\",\n",
    "  \"cayenne\",\n",
    "  \"celeriac\",\n",
    "  \"chayote\",\n",
    "  \"cilantro\",\n",
    "  \"clementine\",\n",
    "  \"cornsalad\",\n",
    "  \"courgette\",\n",
    "  \"currant\",\n",
    "  \"cushaw\",\n",
    "  \"dandelion\",\n",
    "  \"dill\",\n",
    "  \"durian\",\n",
    "  \"endive\",\n",
    "  \"escarole\",\n",
    "  \"fiddlehead\",\n",
    "  \"frisee\",\n",
    "  \"gourd\",\n",
    "  \"jostaberry\",\n",
    "  \"kohlrabi\",\n",
    "  \"lablab\",\n",
    "  \"luffa\",\n",
    "  \"malanga\",\n",
    "  \"mangetout\",\n",
    "  \"mungbean\",\n",
    "  \"navybean\",\n",
    "  \"nopale\",\n",
    "  \"onionchive\",\n",
    "  \"parsley\",\n",
    "  \"parsnip\",\n",
    "  \"pattypan\",\n",
    "  \"peasnap\",\n",
    "  \"persimmon\",\n",
    "  \"pigeonpea\",\n",
    "  \"plantain\",\n",
    "  \"pluot\",\n",
    "  \"pomegranate\",\n",
    "  \"prune\",\n",
    "  \"pumpkin\",\n",
    "  \"radicchio\",\n",
    "  \"rambutan\",\n",
    "  \"rapini\",\n",
    "  \"rocket\",\n",
    "  \"rutabaga\",\n",
    "  \"salsify\",\n",
    "  \"sapote\",\n",
    "  \"scallion\",\n",
    "  \"shallot\",\n",
    "  \"snowpea\",\n",
    "  \"sorrel\",\n",
    "  \"soybean\",\n",
    "  \"spelt\",\n",
    "  \"squash\",\n",
    "  \"tamarind\",\n",
    "  \"tangelo\",\n",
    "  \"tatsoi\",\n",
    "  \"tomatillo\",\n",
    "  \"tuber\",\n",
    "  \"turnip\",\n",
    "  \"waterchestnut\",\n",
    "  \"watermelon\",\n",
    "  \"waxgourd\",\n",
    "  \"yambean\",\n",
    "  \"yautia\",\n",
    "  \"yuca\",\n",
    "  \"ziziphus\",\n",
    "  \"zucchini\",\n",
    "  \"acerola\",\n",
    "  \"ackee\",\n",
    "  \"ambarella\",\n",
    "  \"arugula\",\n",
    "  \"asparagus\",\n",
    "  \"azuki\",\n",
    "  \"bamboo\",\n",
    "  \"basil\",\n",
    "  \"bean\",\n",
    "  \"beet\",\n",
    "  \"bellpepper\",\n",
    "  \"betel\",\n",
    "  \"bokchoy\",\n",
    "  \"broccoli\",\n",
    "  \"broccolini\",\n",
    "  \"brusselsprout\",\n",
    "  \"burdock\",\n",
    "  \"butternut\",\n",
    "  \"calabash\",\n",
    "  \"calamansi\",\n",
    "  \"canarymelon\",\n",
    "  \"cantaloupe\",\n",
    "  \"capuli\",\n",
    "  \"carambola\",\n",
    "  \"carrot\",\n",
    "  \"cassava\",\n",
    "  \"cauliflower\",\n",
    "  \"celery\",\n",
    "  \"chamomile\",\n",
    "  \"cherry\",\n",
    "  \"chickpea\",\n",
    "  \"chicory\",\n",
    "  \"chives\",\n",
    "  \"cilantro\",\n",
    "  \"citrus\",\n",
    "  \"collards\",\n",
    "  \"coriander\",\n",
    "  \"courgette\",\n",
    "  \"cranberry\",\n",
    "  \"cress\",\n",
    "  \"cucumber\",\n",
    "  \"currant\",\n",
    "  \"daikon\",\n",
    "  \"dandelion\",\n",
    "  \"dates\",\n",
    "  \"dragonfruit\",\n",
    "  \"durian\",\n",
    "  \"eggplant\",\n",
    "  \"elderberry\",\n",
    "  \"endive\",\n",
    "  \"fennel\",\n",
    "  \"feijoa\",\n",
    "  \"fig\",\n",
    "  \"fiddlehead\",\n",
    "  \"garbanzo\",\n",
    "  \"garlic\",\n",
    "  \"ginger\",\n",
    "  \"gooseberry\",\n",
    "  \"grape\",\n",
    "  \"grapefruit\",\n",
    "  \"guava\",\n",
    "  \"habanero\",\n",
    "  \"honeydew\",\n",
    "  \"horseradish\",\n",
    "  \"iceberg\",\n",
    "  \"jackfruit\",\n",
    "  \"jalapeno\",\n",
    "  \"jicama\",\n",
    "  \"jostaberry\",\n",
    "  \"jujube\",\n",
    "  \"kabocha\",\n",
    "  \"kale\",\n",
    "  \"kiwi\",\n",
    "  \"kohlrabi\",\n",
    "  \"kumquat\",\n",
    "  \"leek\",\n",
    "  \"lemon\",\n",
    "  \"lentil\",\n",
    "  \"lettuce\",\n",
    "  \"licorice\",\n",
    "  \"lime\",\n",
    "  \"lingonberry\",\n",
    "  \"loquat\",\n",
    "  \"luffa\",\n",
    "  \"lychee\",\n",
    "  \"maca\",\n",
    "  \"mandarin\",\n",
    "  \"mango\",\n",
    "  \"mangosteen\",\n",
    "  \"marrow\",\n",
    "  \"melon\",\n",
    "  \"mungbean\",\n",
    "  \"mustard\",\n",
    "  \"nectarine\",\n",
    "  \"okra\",\n",
    "  \"olive\",\n",
    "  \"onion\",\n",
    "  \"orange\",\n",
    "  \"oregano\",\n",
    "  \"papaya\",\n",
    "  \"parsley\",\n",
    "  \"parsnip\",\n",
    "  \"passionfruit\",\n",
    "  \"pea\",\n",
    "  \"peach\",\n",
    "  \"peanut\",\n",
    "  \"pear\",\n",
    "  \"pecan\",\n",
    "  \"pepper\",\n",
    "  \"persimmon\",\n",
    "  \"pineapple\",\n",
    "  \"pistachio\",\n",
    "  \"plum\",\n",
    "  \"pomegranate\",\n",
    "  \"pomelo\",\n",
    "  \"potato\",\n",
    "  \"pumpkin\",\n",
    "  \"quince\",\n",
    "  \"radish\",\n",
    "  \"rambutan\",\n",
    "  \"rapini\",\n",
    "  \"raspberry\",\n",
    "  \"redcurrant\",\n",
    "  \"rhubarb\",\n",
    "  \"rocket\",\n",
    "  \"rutabaga\",\n",
    "  \"salsify\",\n",
    "  \"sapote\",\n",
    "  \"scallion\",\n",
    "  \"shallot\",\n",
    "  \"snappea\",\n",
    "  \"sorrel\",\n",
    "  \"soybean\",\n",
    "  \"spinach\",\n",
    "  \"spelt\",\n",
    "  \"squash\",\n",
    "  \"starfruit\",\n",
    "  \"strawberry\",\n",
    "  \"sweetcorn\",\n",
    "  \"sweetpotato\",\n",
    "  \"tamarillo\",\n",
    "  \"tamarind\",\n",
    "  \"tangelo\",\n",
    "  \"tatsoi\",\n",
    "  \"tomatillo\",\n",
    "  \"tomato\",\n",
    "  \"turnip\",\n",
    "  \"ugli\",\n",
    "  \"watercress\",\n",
    "  \"watermelon\",\n",
    "  \"waxgourd\",\n",
    "  \"yam\",\n",
    "  \"yuca\",\n",
    "  \"ziziphus\",\n",
    "  \"zucchini\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJcy4XKT_FDh"
   },
   "outputs": [],
   "source": [
    "# 1. データセット用：動物名+果物・野菜名で計1000種弱\n",
    "NAMES = ANIMALS + FRUITS_VEGGIES\n",
    "\n",
    "# 2. 文字のボキャブラリ作成\n",
    "ALL_CHARS = sorted(set(\"\".join(NAMES)))\n",
    "SPECIAL_TOKENS = [\"<PAD>\", \"<BOS>\", \"<EOS>\"]\n",
    "ALL_TOKENS = SPECIAL_TOKENS + ALL_CHARS\n",
    "VOCAB_SIZE = len(ALL_TOKENS)\n",
    "CHAR2IDX = {ch: i for i, ch in enumerate(ALL_TOKENS)}\n",
    "IDX2CHAR = {i: ch for ch, i in CHAR2IDX.items()}\n",
    "PAD_IDX = CHAR2IDX[\"<PAD>\"]\n",
    "BOS_IDX = CHAR2IDX[\"<BOS>\"]\n",
    "EOS_IDX = CHAR2IDX[\"<EOS>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksVvs9KN_JNG"
   },
   "outputs": [],
   "source": [
    "def encode_word(word, max_len):\n",
    "    tokens = [BOS_IDX] + [CHAR2IDX[c] for c in word] + [EOS_IDX]\n",
    "    tokens += [PAD_IDX] * (max_len - len(tokens))\n",
    "    return tokens\n",
    "\n",
    "def decode_tokens(tokens):\n",
    "    chars = []\n",
    "    for idx in tokens:\n",
    "        if idx == EOS_IDX:\n",
    "            break\n",
    "        if idx >= len(IDX2CHAR):\n",
    "            continue\n",
    "        ch = IDX2CHAR[idx]\n",
    "        if ch not in SPECIAL_TOKENS:\n",
    "            chars.append(ch)\n",
    "    return \"\".join(chars)\n",
    "\n",
    "# 3. PyTorch Dataset\n",
    "class NameDataset(Dataset):\n",
    "    def __init__(self, words, max_len):\n",
    "        self.max_len = max_len\n",
    "        self.data = []\n",
    "        for w in words:\n",
    "            tokens = encode_word(w, max_len)\n",
    "            self.data.append(tokens)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.data[idx]\n",
    "        x = torch.tensor(tokens[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(tokens[1:], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pxQiU4o_Ow_"
   },
   "outputs": [],
   "source": [
    "# 4. シンプルな位置エンコーディング\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        if d_model > 1:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(1)]\n",
    "\n",
    "# 5. miniformer本体（シングルヘッド、1層）\n",
    "class MiniFormer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=32, max_len=16):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, max_len)\n",
    "        # シングルヘッドAttention\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.attn_out = nn.Linear(d_model, d_model)\n",
    "        # FFN\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model)\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        self.max_len = max_len\n",
    "        self.attn_weights = None  # for visualization\n",
    "\n",
    "    def forward(self, x, return_attn=False):\n",
    "        emb = self.embed(x)\n",
    "        emb = self.pos_enc(emb)\n",
    "        # Attention\n",
    "        Q = self.q_linear(emb)\n",
    "        K = self.k_linear(emb)\n",
    "        V = self.v_linear(emb)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.d_model)\n",
    "        # causal mask\n",
    "        mask = torch.triu(torch.ones(scores.size(-2), scores.size(-1)), diagonal=1).bool().to(x.device)\n",
    "        scores = scores.masked_fill(mask, float('-inf'))\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        attn_out = torch.matmul(attn, V)\n",
    "        attn_out = self.attn_out(attn_out)\n",
    "        x1 = self.ln1(emb + attn_out)\n",
    "        x2 = self.ln2(x1 + self.ffn(x1))\n",
    "        logits = self.fc_out(x2)\n",
    "        if return_attn:\n",
    "            self.attn_weights = attn.detach().cpu().numpy()\n",
    "            return logits, attn\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRJ7bId8_Rhv"
   },
   "outputs": [],
   "source": [
    "# 6. 訓練ループ\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits.view(-1, VOCAB_SIZE), y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits.view(-1, VOCAB_SIZE), y.view(-1))\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# 7. 可視化用attention保存関数 (BertViz 形式に近いJSON)\n",
    "def save_attention(attn_matrix, input_tokens, filename=\"attn_weights.json\"):\n",
    "    # attn_matrix: [seq_len, seq_len]\n",
    "    data = {\n",
    "        \"tokens\": input_tokens,\n",
    "        \"attentions\": attn_matrix.tolist()\n",
    "    }\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wExgfISs_V-k",
    "outputId": "ff489a0d-8c9c-4349-c824-069cd79f375a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5: train loss=2.5863, test loss=2.5995\n",
      "Epoch 10: train loss=2.4199, test loss=2.5167\n",
      "Epoch 15: train loss=2.3452, test loss=2.4715\n",
      "Epoch 20: train loss=2.2984, test loss=2.4463\n",
      "Epoch 25: train loss=2.2558, test loss=2.4402\n",
      "Epoch 30: train loss=2.2233, test loss=2.4276\n",
      "Epoch 35: train loss=2.1984, test loss=2.4278\n",
      "Epoch 40: train loss=2.1648, test loss=2.4174\n",
      "Epoch 45: train loss=2.1425, test loss=2.4286\n",
      "Epoch 50: train loss=2.1084, test loss=2.4406\n",
      "Epoch 55: train loss=2.0990, test loss=2.4260\n",
      "Epoch 60: train loss=2.0721, test loss=2.4203\n",
      "Epoch 65: train loss=2.0585, test loss=2.4426\n",
      "Epoch 70: train loss=2.0401, test loss=2.4364\n",
      "Epoch 75: train loss=2.0262, test loss=2.4351\n",
      "Epoch 80: train loss=2.0046, test loss=2.4198\n",
      "Epoch 85: train loss=1.9933, test loss=2.4377\n",
      "Epoch 90: train loss=1.9835, test loss=2.4383\n",
      "Epoch 95: train loss=1.9606, test loss=2.4368\n",
      "Epoch 100: train loss=1.9568, test loss=2.4564\n",
      "CPU times: user 21.4 s, sys: 765 ms, total: 22.2 s\n",
      "Wall time: 24.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 設定\n",
    "max_word_len = max(len(w) for w in NAMES) + 2 # BOS, EOS\n",
    "batch_size = 16\n",
    "d_model = 32\n",
    "#n_epochs = 30\n",
    "n_epochs = 100\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# データ分割\n",
    "random.seed(42)\n",
    "random.shuffle(NAMES)\n",
    "split = int(len(NAMES) * 0.8)\n",
    "train_words = NAMES[:split]\n",
    "test_words = NAMES[split:]\n",
    "\n",
    "train_ds = NameDataset(train_words, max_word_len)\n",
    "test_ds = NameDataset(test_words, max_word_len)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# モデル\n",
    "model = MiniFormer(VOCAB_SIZE, d_model, max_word_len).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "# 学習\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss = evaluate(model, test_loader, criterion, device)\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch:2d}: train loss={train_loss:.4f}, test loss={test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iyr6_wEt_dNQ",
    "outputId": "691fbfe9-acc0-48fa-bf76-f8141ff5da56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: flycatcher\n",
      "Predicted: clo\n",
      "Saved attention weights to attn_weights.json. You can visualize with BertViz or any custom tool.\n"
     ]
    }
   ],
   "source": [
    "sample_word = \"flycatcher\"\n",
    "x = torch.tensor([encode_word(sample_word, max_word_len)[:-1]], dtype=torch.long).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits, attn = model(x, return_attn=True)\n",
    "    pred_indices = logits.argmax(dim=-1)[0].cpu().numpy()\n",
    "    print(f\"Input: {sample_word}\")\n",
    "    print(f\"Predicted: {decode_tokens(pred_indices)}\")\n",
    "    # 可視化用attention保存\n",
    "    input_tokens = [IDX2CHAR[idx] for idx in x[0].cpu().numpy()]\n",
    "    save_attention(attn[0], input_tokens, filename=\"attn_weights.json\")\n",
    "    print(\"Saved attention weights to attn_weights.json. You can visualize with BertViz or any custom tool.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "jK3jwfJ5_lt8",
    "outputId": "47f7bf4f-2937-4244-bbd7-1887e1afaf59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "      \n",
       "        <div id=\"bertviz-1ce7bacce4954701a225205c58e62e51\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
       "            <span style=\"user-select:none\">\n",
       "                Layer: <select id=\"layer\"></select>\n",
       "                \n",
       "            </span>\n",
       "            <div id='vis'></div>\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/**\n",
       " * @fileoverview Transformer Visualization D3 javascript code.\n",
       " *\n",
       " *\n",
       " *  Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n",
       " *\n",
       " * Change log:\n",
       " *\n",
       " * 12/19/18  Jesse Vig   Assorted cleanup. Changed orientation of attention matrices.\n",
       " * 12/29/20  Jesse Vig   Significant refactor.\n",
       " * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n",
       " * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n",
       " * 05/03/21  Jesse Vig   Adjust height of visualization dynamically\n",
       " * 07/25/21  Jesse Vig   Support layer filtering\n",
       " * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n",
       " **/\n",
       "\n",
       "require.config({\n",
       "  paths: {\n",
       "      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n",
       "    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
       "  }\n",
       "});\n",
       "\n",
       "requirejs(['jquery', 'd3'], function ($, d3) {\n",
       "\n",
       "    const params = {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9168000817298889, 0.08319993317127228, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33936378359794617, 0.033335890620946884, 0.6273003220558167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4878334403038025, 0.09077391028404236, 0.31670013070106506, 0.10469246655702591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05451502278447151, 0.0006353901117108762, 0.02057555690407753, 0.46630775928497314, 0.45796629786491394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.048566605895757675, 0.008952820673584938, 0.10897260904312134, 0.12688474357128143, 0.35952767729759216, 0.3470955491065979, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0028659445233643055, 0.003952356521040201, 0.021778058260679245, 0.16336531937122345, 0.031023552641272545, 0.732170581817627, 0.04484416916966438, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013502986170351505, 0.0026021343655884266, 0.005151658784598112, 0.015556453727185726, 0.02428344450891018, 0.4163690209388733, 0.45411211252212524, 0.06842218339443207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0035490826703608036, 0.001684783142991364, 0.0007161113317124546, 0.9661531448364258, 0.0028344085440039635, 0.016694972291588783, 0.002342439256608486, 0.0022737099789083004, 0.0037513801362365484, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01836628094315529, 0.009264961816370487, 0.03383398801088333, 0.12363164126873016, 0.012337783351540565, 0.14584629237651825, 0.06603467464447021, 0.02837008237838745, 0.49170076847076416, 0.07061349600553513, 0.0, 0.0, 0.0, 0.0], [0.0027884675655514, 0.014560502953827381, 0.004734909627586603, 0.009480929933488369, 0.021202482283115387, 0.02708684653043747, 0.026170503348112106, 0.4051769971847534, 0.13346953690052032, 0.3548363745212555, 0.0004923433298245072, 0.0, 0.0, 0.0], [0.014920460991561413, 0.33417174220085144, 0.015313677489757538, 0.008194229565560818, 0.004059783648699522, 0.21521639823913574, 0.021938279271125793, 0.04128141701221466, 0.07781936973333359, 0.2549870014190674, 0.0029018267523497343, 0.00919583160430193, 0.0, 0.0], [0.016899986192584038, 0.4318644106388092, 0.02111607976257801, 0.015106281265616417, 0.0002536697720643133, 0.18419024348258972, 0.004240313079208136, 0.0015404372243210673, 0.12707257270812988, 0.03455083444714546, 0.10171353071928024, 0.028491847217082977, 0.03295980021357536, 0.0], [0.0181015245616436, 0.47343435883522034, 0.023075513541698456, 0.01673797145485878, 0.00016393899568356574, 0.1670263707637787, 0.0033287417609244585, 0.0006739901145920157, 0.08284451067447662, 0.014371093362569809, 0.14269675314426422, 0.029060380533337593, 0.018039071932435036, 0.010445847176015377]]]], \"left_text\": [\"<BOS>\", \"f\", \"l\", \"y\", \"c\", \"a\", \"t\", \"c\", \"h\", \"e\", \"r\", \"<EOS>\", \"<PAD>\", \"<PAD>\"], \"right_text\": [\"<BOS>\", \"f\", \"l\", \"y\", \"c\", \"a\", \"t\", \"c\", \"h\", \"e\", \"r\", \"<EOS>\", \"<PAD>\", \"<PAD>\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-1ce7bacce4954701a225205c58e62e51\", \"layer\": null, \"heads\": null, \"include_layers\": [0]}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9168000817298889, 0.08319993317127228, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33936378359794617, 0.033335890620946884, 0.6273003220558167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4878334403038025, 0.09077391028404236, 0.31670013070106506, 0.10469246655702591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05451502278447151, 0.0006353901117108762, 0.02057555690407753, 0.46630775928497314, 0.45796629786491394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.048566605895757675, 0.008952820673584938, 0.10897260904312134, 0.12688474357128143, 0.35952767729759216, 0.3470955491065979, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0028659445233643055, 0.003952356521040201, 0.021778058260679245, 0.16336531937122345, 0.031023552641272545, 0.732170581817627, 0.04484416916966438, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013502986170351505, 0.0026021343655884266, 0.005151658784598112, 0.015556453727185726, 0.02428344450891018, 0.4163690209388733, 0.45411211252212524, 0.06842218339443207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0035490826703608036, 0.001684783142991364, 0.0007161113317124546, 0.9661531448364258, 0.0028344085440039635, 0.016694972291588783, 0.002342439256608486, 0.0022737099789083004, 0.0037513801362365484, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01836628094315529, 0.009264961816370487, 0.03383398801088333, 0.12363164126873016, 0.012337783351540565, 0.14584629237651825, 0.06603467464447021, 0.02837008237838745, 0.49170076847076416, 0.07061349600553513, 0.0, 0.0, 0.0, 0.0], [0.0027884675655514, 0.014560502953827381, 0.004734909627586603, 0.009480929933488369, 0.021202482283115387, 0.02708684653043747, 0.026170503348112106, 0.4051769971847534, 0.13346953690052032, 0.3548363745212555, 0.0004923433298245072, 0.0, 0.0, 0.0], [0.014920460991561413, 0.33417174220085144, 0.015313677489757538, 0.008194229565560818, 0.004059783648699522, 0.21521639823913574, 0.021938279271125793, 0.04128141701221466, 0.07781936973333359, 0.2549870014190674, 0.0029018267523497343, 0.00919583160430193, 0.0, 0.0], [0.016899986192584038, 0.4318644106388092, 0.02111607976257801, 0.015106281265616417, 0.0002536697720643133, 0.18419024348258972, 0.004240313079208136, 0.0015404372243210673, 0.12707257270812988, 0.03455083444714546, 0.10171353071928024, 0.028491847217082977, 0.03295980021357536, 0.0], [0.0181015245616436, 0.47343435883522034, 0.023075513541698456, 0.01673797145485878, 0.00016393899568356574, 0.1670263707637787, 0.0033287417609244585, 0.0006739901145920157, 0.08284451067447662, 0.014371093362569809, 0.14269675314426422, 0.029060380533337593, 0.018039071932435036, 0.010445847176015377]]]], \"left_text\": [\"<BOS>\", \"f\", \"l\", \"y\", \"c\", \"a\", \"t\", \"c\", \"h\", \"e\", \"r\", \"<EOS>\", \"<PAD>\", \"<PAD>\"], \"right_text\": [\"<BOS>\", \"f\", \"l\", \"y\", \"c\", \"a\", \"t\", \"c\", \"h\", \"e\", \"r\", \"<EOS>\", \"<PAD>\", \"<PAD>\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-1ce7bacce4954701a225205c58e62e51\", \"layer\": null, \"heads\": null, \"include_layers\": [0]} is a template marker that is replaced by actual params.\n",
       "    const TEXT_SIZE = 15;\n",
       "    const BOXWIDTH = 110;\n",
       "    const BOXHEIGHT = 22.5;\n",
       "    const MATRIX_WIDTH = 115;\n",
       "    const CHECKBOX_SIZE = 20;\n",
       "    const TEXT_TOP = 30;\n",
       "\n",
       "    console.log(\"d3 version\", d3.version)\n",
       "    let headColors;\n",
       "    try {\n",
       "        headColors = d3.scaleOrdinal(d3.schemeCategory10);\n",
       "    } catch (err) {\n",
       "        console.log('Older d3 version')\n",
       "        headColors = d3.scale.category10();\n",
       "    }\n",
       "    let config = {};\n",
       "    initialize();\n",
       "    renderVis();\n",
       "\n",
       "    function initialize() {\n",
       "        config.attention = params['attention'];\n",
       "        config.filter = params['default_filter'];\n",
       "        config.rootDivId = params['root_div_id'];\n",
       "        config.nLayers = config.attention[config.filter]['attn'].length;\n",
       "        config.nHeads = config.attention[config.filter]['attn'][0].length;\n",
       "        config.layers = params['include_layers']\n",
       "\n",
       "        if (params['heads']) {\n",
       "            config.headVis = new Array(config.nHeads).fill(false);\n",
       "            params['heads'].forEach(x => config.headVis[x] = true);\n",
       "        } else {\n",
       "            config.headVis = new Array(config.nHeads).fill(true);\n",
       "        }\n",
       "        config.initialTextLength = config.attention[config.filter].right_text.length;\n",
       "        config.layer_seq = (params['layer'] == null ? 0 : config.layers.findIndex(layer => params['layer'] === layer));\n",
       "        config.layer = config.layers[config.layer_seq]\n",
       "\n",
       "        let layerEl = $(`#${config.rootDivId} #layer`);\n",
       "        for (const layer of config.layers) {\n",
       "            layerEl.append($(\"<option />\").val(layer).text(layer));\n",
       "        }\n",
       "        layerEl.val(config.layer).change();\n",
       "        layerEl.on('change', function (e) {\n",
       "            config.layer = +e.currentTarget.value;\n",
       "            config.layer_seq = config.layers.findIndex(layer => config.layer === layer);\n",
       "            renderVis();\n",
       "        });\n",
       "\n",
       "        $(`#${config.rootDivId} #filter`).on('change', function (e) {\n",
       "            config.filter = e.currentTarget.value;\n",
       "            renderVis();\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function renderVis() {\n",
       "\n",
       "        // Load parameters\n",
       "        const attnData = config.attention[config.filter];\n",
       "        const leftText = attnData.left_text;\n",
       "        const rightText = attnData.right_text;\n",
       "\n",
       "        // Select attention for given layer\n",
       "        const layerAttention = attnData.attn[config.layer_seq];\n",
       "\n",
       "        // Clear vis\n",
       "        $(`#${config.rootDivId} #vis`).empty();\n",
       "\n",
       "        // Determine size of visualization\n",
       "        const height = Math.max(leftText.length, rightText.length) * BOXHEIGHT + TEXT_TOP;\n",
       "        const svg = d3.select(`#${config.rootDivId} #vis`)\n",
       "            .append('svg')\n",
       "            .attr(\"width\", \"100%\")\n",
       "            .attr(\"height\", height + \"px\");\n",
       "\n",
       "        // Display tokens on left and right side of visualization\n",
       "        renderText(svg, leftText, true, layerAttention, 0);\n",
       "        renderText(svg, rightText, false, layerAttention, MATRIX_WIDTH + BOXWIDTH);\n",
       "\n",
       "        // Render attention arcs\n",
       "        renderAttention(svg, layerAttention);\n",
       "\n",
       "        // Draw squares at top of visualization, one for each head\n",
       "        drawCheckboxes(0, svg, layerAttention);\n",
       "    }\n",
       "\n",
       "    function renderText(svg, text, isLeft, attention, leftPos) {\n",
       "\n",
       "        const textContainer = svg.append(\"svg:g\")\n",
       "            .attr(\"id\", isLeft ? \"left\" : \"right\");\n",
       "\n",
       "        // Add attention highlights superimposed over words\n",
       "        textContainer.append(\"g\")\n",
       "            .classed(\"attentionBoxes\", true)\n",
       "            .selectAll(\"g\")\n",
       "            .data(attention)\n",
       "            .enter()\n",
       "            .append(\"g\")\n",
       "            .attr(\"head-index\", (d, i) => i)\n",
       "            .selectAll(\"rect\")\n",
       "            .data(d => isLeft ? d : transpose(d)) // if right text, transpose attention to get right-to-left weights\n",
       "            .enter()\n",
       "            .append(\"rect\")\n",
       "            .attr(\"x\", function () {\n",
       "                var headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
       "                return leftPos + boxOffsets(headIndex);\n",
       "            })\n",
       "            .attr(\"y\", (+1) * BOXHEIGHT)\n",
       "            .attr(\"width\", BOXWIDTH / activeHeads())\n",
       "            .attr(\"height\", BOXHEIGHT)\n",
       "            .attr(\"fill\", function () {\n",
       "                return headColors(+this.parentNode.getAttribute(\"head-index\"))\n",
       "            })\n",
       "            .style(\"opacity\", 0.0);\n",
       "\n",
       "        const tokenContainer = textContainer.append(\"g\").selectAll(\"g\")\n",
       "            .data(text)\n",
       "            .enter()\n",
       "            .append(\"g\");\n",
       "\n",
       "        // Add gray background that appears when hovering over text\n",
       "        tokenContainer.append(\"rect\")\n",
       "            .classed(\"background\", true)\n",
       "            .style(\"opacity\", 0.0)\n",
       "            .attr(\"fill\", \"lightgray\")\n",
       "            .attr(\"x\", leftPos)\n",
       "            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n",
       "            .attr(\"width\", BOXWIDTH)\n",
       "            .attr(\"height\", BOXHEIGHT);\n",
       "\n",
       "        // Add token text\n",
       "        const textEl = tokenContainer.append(\"text\")\n",
       "            .text(d => d)\n",
       "            .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "            .style(\"cursor\", \"default\")\n",
       "            .style(\"-webkit-user-select\", \"none\")\n",
       "            .attr(\"x\", leftPos)\n",
       "            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT);\n",
       "\n",
       "        if (isLeft) {\n",
       "            textEl.style(\"text-anchor\", \"end\")\n",
       "                .attr(\"dx\", BOXWIDTH - 0.5 * TEXT_SIZE)\n",
       "                .attr(\"dy\", TEXT_SIZE);\n",
       "        } else {\n",
       "            textEl.style(\"text-anchor\", \"start\")\n",
       "                .attr(\"dx\", +0.5 * TEXT_SIZE)\n",
       "                .attr(\"dy\", TEXT_SIZE);\n",
       "        }\n",
       "\n",
       "        tokenContainer.on(\"mouseover\", function (d, index) {\n",
       "\n",
       "            // Show gray background for moused-over token\n",
       "            textContainer.selectAll(\".background\")\n",
       "                .style(\"opacity\", (d, i) => i === index ? 1.0 : 0.0)\n",
       "\n",
       "            // Reset visibility attribute for any previously highlighted attention arcs\n",
       "            svg.select(\"#attention\")\n",
       "                .selectAll(\"line[visibility='visible']\")\n",
       "                .attr(\"visibility\", null)\n",
       "\n",
       "            // Hide group containing attention arcs\n",
       "            svg.select(\"#attention\").attr(\"visibility\", \"hidden\");\n",
       "\n",
       "            // Set to visible appropriate attention arcs to be highlighted\n",
       "            if (isLeft) {\n",
       "                svg.select(\"#attention\").selectAll(\"line[left-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n",
       "            } else {\n",
       "                svg.select(\"#attention\").selectAll(\"line[right-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n",
       "            }\n",
       "\n",
       "            // Update color boxes superimposed over tokens\n",
       "            const id = isLeft ? \"right\" : \"left\";\n",
       "            const leftPos = isLeft ? MATRIX_WIDTH + BOXWIDTH : 0;\n",
       "            svg.select(\"#\" + id)\n",
       "                .selectAll(\".attentionBoxes\")\n",
       "                .selectAll(\"g\")\n",
       "                .attr(\"head-index\", (d, i) => i)\n",
       "                .selectAll(\"rect\")\n",
       "                .attr(\"x\", function () {\n",
       "                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
       "                    return leftPos + boxOffsets(headIndex);\n",
       "                })\n",
       "                .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n",
       "                .attr(\"width\", BOXWIDTH / activeHeads())\n",
       "                .attr(\"height\", BOXHEIGHT)\n",
       "                .style(\"opacity\", function (d) {\n",
       "                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
       "                    if (config.headVis[headIndex])\n",
       "                        if (d) {\n",
       "                            return d[index];\n",
       "                        } else {\n",
       "                            return 0.0;\n",
       "                        }\n",
       "                    else\n",
       "                        return 0.0;\n",
       "                });\n",
       "        });\n",
       "\n",
       "        textContainer.on(\"mouseleave\", function () {\n",
       "\n",
       "            // Unhighlight selected token\n",
       "            d3.select(this).selectAll(\".background\")\n",
       "                .style(\"opacity\", 0.0);\n",
       "\n",
       "            // Reset visibility attributes for previously selected lines\n",
       "            svg.select(\"#attention\")\n",
       "                .selectAll(\"line[visibility='visible']\")\n",
       "                .attr(\"visibility\", null) ;\n",
       "            svg.select(\"#attention\").attr(\"visibility\", \"visible\");\n",
       "\n",
       "            // Reset highlights superimposed over tokens\n",
       "            svg.selectAll(\".attentionBoxes\")\n",
       "                .selectAll(\"g\")\n",
       "                .selectAll(\"rect\")\n",
       "                .style(\"opacity\", 0.0);\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function renderAttention(svg, attention) {\n",
       "\n",
       "        // Remove previous dom elements\n",
       "        svg.select(\"#attention\").remove();\n",
       "\n",
       "        // Add new elements\n",
       "        svg.append(\"g\")\n",
       "            .attr(\"id\", \"attention\") // Container for all attention arcs\n",
       "            .selectAll(\".headAttention\")\n",
       "            .data(attention)\n",
       "            .enter()\n",
       "            .append(\"g\")\n",
       "            .classed(\"headAttention\", true) // Group attention arcs by head\n",
       "            .attr(\"head-index\", (d, i) => i)\n",
       "            .selectAll(\".tokenAttention\")\n",
       "            .data(d => d)\n",
       "            .enter()\n",
       "            .append(\"g\")\n",
       "            .classed(\"tokenAttention\", true) // Group attention arcs by left token\n",
       "            .attr(\"left-token-index\", (d, i) => i)\n",
       "            .selectAll(\"line\")\n",
       "            .data(d => d)\n",
       "            .enter()\n",
       "            .append(\"line\")\n",
       "            .attr(\"x1\", BOXWIDTH)\n",
       "            .attr(\"y1\", function () {\n",
       "                const leftTokenIndex = +this.parentNode.getAttribute(\"left-token-index\")\n",
       "                return TEXT_TOP + leftTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2)\n",
       "            })\n",
       "            .attr(\"x2\", BOXWIDTH + MATRIX_WIDTH)\n",
       "            .attr(\"y2\", (d, rightTokenIndex) => TEXT_TOP + rightTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2))\n",
       "            .attr(\"stroke-width\", 2)\n",
       "            .attr(\"stroke\", function () {\n",
       "                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n",
       "                return headColors(headIndex)\n",
       "            })\n",
       "            .attr(\"left-token-index\", function () {\n",
       "                return +this.parentNode.getAttribute(\"left-token-index\")\n",
       "            })\n",
       "            .attr(\"right-token-index\", (d, i) => i)\n",
       "        ;\n",
       "        updateAttention(svg)\n",
       "    }\n",
       "\n",
       "    function updateAttention(svg) {\n",
       "        svg.select(\"#attention\")\n",
       "            .selectAll(\"line\")\n",
       "            .attr(\"stroke-opacity\", function (d) {\n",
       "                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n",
       "                // If head is selected\n",
       "                if (config.headVis[headIndex]) {\n",
       "                    // Set opacity to attention weight divided by number of active heads\n",
       "                    return d / activeHeads()\n",
       "                } else {\n",
       "                    return 0.0;\n",
       "                }\n",
       "            })\n",
       "    }\n",
       "\n",
       "    function boxOffsets(i) {\n",
       "        const numHeadsAbove = config.headVis.reduce(\n",
       "            function (acc, val, cur) {\n",
       "                return val && cur < i ? acc + 1 : acc;\n",
       "            }, 0);\n",
       "        return numHeadsAbove * (BOXWIDTH / activeHeads());\n",
       "    }\n",
       "\n",
       "    function activeHeads() {\n",
       "        return config.headVis.reduce(function (acc, val) {\n",
       "            return val ? acc + 1 : acc;\n",
       "        }, 0);\n",
       "    }\n",
       "\n",
       "    function drawCheckboxes(top, svg) {\n",
       "        const checkboxContainer = svg.append(\"g\");\n",
       "        const checkbox = checkboxContainer.selectAll(\"rect\")\n",
       "            .data(config.headVis)\n",
       "            .enter()\n",
       "            .append(\"rect\")\n",
       "            .attr(\"fill\", (d, i) => headColors(i))\n",
       "            .attr(\"x\", (d, i) => i * CHECKBOX_SIZE)\n",
       "            .attr(\"y\", top)\n",
       "            .attr(\"width\", CHECKBOX_SIZE)\n",
       "            .attr(\"height\", CHECKBOX_SIZE);\n",
       "\n",
       "        function updateCheckboxes() {\n",
       "            checkboxContainer.selectAll(\"rect\")\n",
       "                .data(config.headVis)\n",
       "                .attr(\"fill\", (d, i) => d ? headColors(i): lighten(headColors(i)));\n",
       "        }\n",
       "\n",
       "        updateCheckboxes();\n",
       "\n",
       "        checkbox.on(\"click\", function (d, i) {\n",
       "            if (config.headVis[i] && activeHeads() === 1) return;\n",
       "            config.headVis[i] = !config.headVis[i];\n",
       "            updateCheckboxes();\n",
       "            updateAttention(svg);\n",
       "        });\n",
       "\n",
       "        checkbox.on(\"dblclick\", function (d, i) {\n",
       "            // If we double click on the only active head then reset\n",
       "            if (config.headVis[i] && activeHeads() === 1) {\n",
       "                config.headVis = new Array(config.nHeads).fill(true);\n",
       "            } else {\n",
       "                config.headVis = new Array(config.nHeads).fill(false);\n",
       "                config.headVis[i] = true;\n",
       "            }\n",
       "            updateCheckboxes();\n",
       "            updateAttention(svg);\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function lighten(color) {\n",
       "        const c = d3.hsl(color);\n",
       "        const increment = (1 - c.l) * 0.6;\n",
       "        c.l += increment;\n",
       "        c.s -= increment;\n",
       "        return c;\n",
       "    }\n",
       "\n",
       "    function transpose(mat) {\n",
       "        return mat[0].map(function (col, i) {\n",
       "            return mat.map(function (row) {\n",
       "                return row[i];\n",
       "            });\n",
       "        });\n",
       "    }\n",
       "\n",
       "});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from bertviz import head_view\n",
    "\n",
    "# attn_weights.jsonを読み込む\n",
    "with open('attn_weights.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "tokens = data['tokens']  # トークン列\n",
    "attn = data['attentions']  # (seq_len, seq_len) のリスト\n",
    "\n",
    "# BertViz用に次元調整\n",
    "attn_tensor = torch.tensor(attn).unsqueeze(0).unsqueeze(0)  # (1, 1, seq_len, seq_len)\n",
    "\n",
    "# BertVizで可視化\n",
    "head_view(attention=[attn_tensor], tokens=tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFgYWQRB6aI9"
   },
   "source": [
    "## Hugging Face transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ceJ6pLEKpqFG"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "\n",
    "# 2. Transformer Decoder（self-attnもcross-attnも返す）\n",
    "class SimpleTransformerDecoder(nn.Module):\n",
    "    def __init__(self, d_model=64, max_len=16, nhead=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, d_model)\n",
    "        self.pos_enc = nn.Parameter(self._init_pe(max_len, d_model), requires_grad=False)\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward=128, batch_first=True)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.max_len = max_len\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.nhead = nhead\n",
    "\n",
    "    def _init_pe(self, max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        if d_model > 1:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_key_padding_mask=None, memory_key_padding_mask=None, return_attn=False):\n",
    "        tgt_emb = self.embedding(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        self_attn_weights_layers = []\n",
    "        cross_attn_weights_layers = []\n",
    "        output = tgt_emb\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
    "        for layer in self.layers:\n",
    "            # Self-attn\n",
    "            tgt2, self_attn_weights = layer.self_attn(\n",
    "                output, output, output,\n",
    "                attn_mask=tgt_mask,\n",
    "                key_padding_mask=tgt_key_padding_mask,\n",
    "                need_weights=True,\n",
    "                average_attn_weights=False\n",
    "            )\n",
    "            output = output + layer.dropout1(tgt2)\n",
    "            output = layer.norm1(output)\n",
    "            # Cross-attn\n",
    "            tgt2, cross_attn_weights = layer.multihead_attn(\n",
    "                output, memory, memory,\n",
    "                key_padding_mask=memory_key_padding_mask,\n",
    "                need_weights=True,\n",
    "                average_attn_weights=False\n",
    "            )\n",
    "            output = output + layer.dropout2(tgt2)\n",
    "            output = layer.norm2(output)\n",
    "            # FFN\n",
    "            tgt2 = layer.linear2(layer.dropout(layer.activation(layer.linear1(output))))\n",
    "            output = output + layer.dropout3(tgt2)\n",
    "            output = layer.norm3(output)\n",
    "            if return_attn:\n",
    "                self_attn_weights_layers.append(self_attn_weights.detach().cpu())\n",
    "                cross_attn_weights_layers.append(cross_attn_weights.detach().cpu())\n",
    "        if return_attn:\n",
    "            return output, self_attn_weights_layers, cross_attn_weights_layers\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "# 3. フルTransformer: Encoder + カスタムDecoder\n",
    "class FullTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=64, max_len=16, nhead=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = nn.Parameter(self._init_pe(max_len, d_model), requires_grad=False)\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=128, batch_first=True),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.decoder = SimpleTransformerDecoder(d_model, max_len, nhead, num_layers)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        self.max_len = max_len\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def _init_pe(self, max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        if d_model > 1:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None, return_attn=False):\n",
    "        src_emb = self.embedding(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        memory = self.encoder(src_emb, src_key_padding_mask=src_key_padding_mask)\n",
    "        if return_attn:\n",
    "            dec_out, self_attn_layers, cross_attn_layers = self.decoder(\n",
    "                tgt, memory,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_key_padding_mask,\n",
    "                return_attn=True\n",
    "            )\n",
    "            logits = self.fc_out(dec_out)\n",
    "            return logits, self_attn_layers, cross_attn_layers\n",
    "        else:\n",
    "            dec_out = self.decoder(\n",
    "                tgt, memory,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_key_padding_mask,\n",
    "                return_attn=False\n",
    "            )\n",
    "            logits = self.fc_out(dec_out)\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6b4ktw6l6mFE"
   },
   "outputs": [],
   "source": [
    "# 4. 訓練ループ\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        src_key_padding_mask = (x == PAD_IDX)\n",
    "        tgt_key_padding_mask = (x == PAD_IDX)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x, x, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "        loss = criterion(logits.view(-1, VOCAB_SIZE), y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            src_key_padding_mask = (x == PAD_IDX)\n",
    "            tgt_key_padding_mask = (x == PAD_IDX)\n",
    "            logits = model(x, x, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "            loss = criterion(logits.view(-1, VOCAB_SIZE), y.view(-1))\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def save_attention_bertviz(attn_layers, tokens, filename=\"self_attn_bertviz.json\"):\n",
    "    \"\"\"\n",
    "    attn_layers: [num_layers][nhead, tgt_len, tgt_len]\n",
    "    tokens: トークン列\n",
    "    \"\"\"\n",
    "    all_layers = []\n",
    "    for layer in attn_layers:\n",
    "        layer_heads = []\n",
    "        for head in layer:\n",
    "            if isinstance(head, torch.Tensor):\n",
    "                head = head.cpu().numpy()\n",
    "            layer_heads.append(head.tolist())\n",
    "        all_layers.append(layer_heads)\n",
    "    data = {\n",
    "        \"all\": all_layers,\n",
    "        \"tokens\": tokens\n",
    "    }\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"Saved self-attention to {filename} (bertviz format, with tokens)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pqc1gmcRZeE4",
    "outputId": "20618931-fcbf-4ae2-c8e0-6eb7fb6bb7c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5: train loss=0.4274, test loss=0.3032\n",
      "Epoch 10: train loss=0.1081, test loss=0.0877\n",
      "Epoch 15: train loss=0.0651, test loss=0.0935\n",
      "Epoch 20: train loss=0.0320, test loss=0.0330\n",
      "Epoch 25: train loss=0.0292, test loss=0.0297\n",
      "Epoch 30: train loss=0.0149, test loss=0.0267\n",
      "Epoch 35: train loss=0.0275, test loss=0.0224\n",
      "Epoch 40: train loss=0.0177, test loss=0.0463\n",
      "Epoch 45: train loss=0.0081, test loss=0.0313\n",
      "Epoch 50: train loss=0.0247, test loss=0.0218\n",
      "Epoch 55: train loss=0.0088, test loss=0.0149\n",
      "Epoch 60: train loss=0.0454, test loss=0.0698\n",
      "Epoch 65: train loss=0.0185, test loss=0.0278\n",
      "Epoch 70: train loss=0.0152, test loss=0.0160\n",
      "Epoch 75: train loss=0.0108, test loss=0.0421\n",
      "Epoch 80: train loss=0.0263, test loss=0.0218\n",
      "Epoch 85: train loss=0.0042, test loss=0.0340\n",
      "Epoch 90: train loss=0.0121, test loss=0.0033\n",
      "Epoch 95: train loss=0.0133, test loss=0.0253\n",
      "Epoch 100: train loss=0.0101, test loss=0.0208\n",
      "Saved self-attention to self_attn_bertviz.json (bertviz format, with tokens)\n",
      "Saved self-attention weights to self_attn_bertviz.json. You can visualize with BertViz.\n",
      "CPU times: user 1min 10s, sys: 314 ms, total: 1min 10s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_word_len = max(len(w) for w in NAMES) + 2\n",
    "batch_size = 16\n",
    "d_model = 64\n",
    "n_epochs = 100\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "random.shuffle(NAMES)\n",
    "split = int(len(NAMES) * 0.8)\n",
    "train_words = NAMES[:split]\n",
    "test_words = NAMES[split:]\n",
    "\n",
    "train_ds = NameDataset(train_words, max_word_len)\n",
    "test_ds = NameDataset(test_words, max_word_len)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = FullTransformer(VOCAB_SIZE, d_model, max_word_len, nhead=4, num_layers=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss = evaluate(model, test_loader, criterion, device)\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch:2d}: train loss={train_loss:.4f}, test loss={test_loss:.4f}\")\n",
    "\n",
    "# ---- 正解系列（teacher forcing）でセルフアテンション保存 ----\n",
    "sample_word = \"flycatcher\"\n",
    "x = torch.tensor([encode_word(sample_word, max_word_len)[:-1]], dtype=torch.long).to(device)\n",
    "tgt = torch.tensor([encode_word(sample_word, max_word_len)[:-1]], dtype=torch.long).to(device)  # 正解系列\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits, self_attn_layers, cross_attn_layers = model(\n",
    "        x, tgt,\n",
    "        src_key_padding_mask=(x == PAD_IDX),\n",
    "        tgt_key_padding_mask=(tgt == PAD_IDX),\n",
    "        return_attn=True\n",
    "    )\n",
    "    # self_attn_layers: [num_layers][batch, nhead, tgt_len, tgt_len]\n",
    "    attn_layers = [\n",
    "        [self_attn_layers[l][0, h].cpu().numpy() for h in range(self_attn_layers[l].shape[1])]\n",
    "        for l in range(len(self_attn_layers))\n",
    "    ]\n",
    "    tokens = [IDX2CHAR[idx] for idx in tgt[0].cpu().numpy()]\n",
    "    save_attention_bertviz(attn_layers, tokens, filename=\"self_attn_bertviz.json\")\n",
    "    print(\"Saved self-attention weights to self_attn_bertviz.json. You can visualize with BertViz.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "ipgNJSyI7JDJ",
    "outputId": "e8c4be96-6b3c-4dfe-bcd1-ddda6885f51b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_all.shape: (2, 4, 14, 14), tokens: ['<BOS>', 'f', 'l', 'y', 'c', 'a', 't', 'c', 'h', 'e', 'r', '<EOS>', '<PAD>', '<PAD>']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "      \n",
       "        <div id=\"bertviz-4e8a4e4f170e4d00b535b768f480fdfe\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
       "            <span style=\"user-select:none\">\n",
       "                Layer: <select id=\"layer\"></select>\n",
       "                \n",
       "            </span>\n",
       "            <div id='vis'></div>\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/**\n",
       " * @fileoverview Transformer Visualization D3 javascript code.\n",
       " *\n",
       " *\n",
       " *  Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n",
       " *\n",
       " * Change log:\n",
       " *\n",
       " * 12/19/18  Jesse Vig   Assorted cleanup. Changed orientation of attention matrices.\n",
       " * 12/29/20  Jesse Vig   Significant refactor.\n",
       " * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n",
       " * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n",
       " * 05/03/21  Jesse Vig   Adjust height of visualization dynamically\n",
       " * 07/25/21  Jesse Vig   Support layer filtering\n",
       " * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n",
       " **/\n",
       "\n",
       "require.config({\n",
       "  paths: {\n",
       "      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n",
       "    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
       "  }\n",
       "});\n",
       "\n",
       "requirejs(['jquery', 'd3'], function ($, d3) {\n",
       "\n",
       "    const params = {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.724626898765564, 0.27537307143211365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1684461236000061, 0.1115279570221901, 0.720025897026062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.029132423922419548, 0.04113442823290825, 0.9009055495262146, 0.028827643021941185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010972388088703156, 0.008973889984190464, 0.040146831423044205, 0.036990247666835785, 0.9029166102409363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004904638044536114, 0.0013782645110040903, 0.005036907270550728, 0.008212740533053875, 0.2641729414463043, 0.7207086682319641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0009746559080667794, 0.0008959718397818506, 0.0021742319222539663, 0.00540682440623641, 0.06183263659477234, 0.39220893383026123, 0.5365068316459656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002428296720609069, 0.0015334871131926775, 0.003229082329198718, 0.0035730230156332254, 0.021443935111165047, 0.5649051070213318, 0.23574990034103394, 0.16713713109493256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005359534174203873, 0.008710755035281181, 0.015554056502878666, 0.020073745399713516, 0.06700840592384338, 0.14202512800693512, 0.18731273710727692, 0.18625080585479736, 0.367704838514328, 0.0, 0.0, 0.0, 0.0, 0.0], [8.504252036800608e-05, 0.00023528042947873473, 0.0006260576192289591, 0.0007276212563738227, 0.005674776155501604, 0.0417969711124897, 0.08456667512655258, 0.04192569851875305, 0.1542774885892868, 0.6700844764709473, 0.0, 0.0, 0.0, 0.0], [3.647639096016064e-05, 0.00011635245755314827, 0.00026732328115031123, 0.0003926251665689051, 0.003144270973280072, 0.04079451784491539, 0.07613306492567062, 0.03364671766757965, 0.1715421825647354, 0.39352843165397644, 0.28039810061454773, 0.0, 0.0, 0.0], [0.032451849430799484, 0.017949745059013367, 0.01732417196035385, 0.05450862646102905, 0.059766724705696106, 0.12705129384994507, 0.15503446757793427, 0.08913806080818176, 0.15542979538440704, 0.08211970329284668, 0.13604171574115753, 0.0731838271021843, 0.0, 0.0], [0.027014754712581635, 0.03181717172265053, 0.034102752804756165, 0.01801958680152893, 0.012956619262695312, 0.07816128432750702, 0.04855794459581375, 0.026575841009616852, 0.15788380801677704, 0.14508014917373657, 0.3689577281475067, 0.05087234079837799, 0.0, 0.0], [0.04780331999063492, 0.04679042100906372, 0.048802100121974945, 0.022626640275120735, 0.01604725793004036, 0.08953594416379929, 0.043370943516492844, 0.02934807352721691, 0.15936627984046936, 0.12515224516391754, 0.32143649458885193, 0.04972030967473984, 0.0, 0.0]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4110870063304901, 0.5889129638671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16972269117832184, 0.20270906388759613, 0.627568244934082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08933189511299133, 0.09739500284194946, 0.7171462774276733, 0.0961267352104187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08247150480747223, 0.12218286842107773, 0.2283076047897339, 0.11560782045125961, 0.45143020153045654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05360184609889984, 0.04008046165108681, 0.1287464201450348, 0.08797754347324371, 0.44119247794151306, 0.2484012395143509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.039485689252614975, 0.03861238807439804, 0.03143446147441864, 0.0211022961884737, 0.09542834013700485, 0.5101359486579895, 0.2638009488582611, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.026426047086715698, 0.0228985957801342, 0.04010944813489914, 0.014966877177357674, 0.06548593938350677, 0.3337010443210602, 0.1271722912788391, 0.3692397177219391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03793273866176605, 0.026227010414004326, 0.041103705763816833, 0.004962393082678318, 0.021144136786460876, 0.12746919691562653, 0.04975343868136406, 0.12392136454582214, 0.5674859285354614, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00402842229232192, 0.0037421416491270065, 0.013327698223292828, 0.0010023198556154966, 0.022974679246544838, 0.0294973012059927, 0.05279850587248802, 0.11170019209384918, 0.4291641116142273, 0.33176469802856445, 0.0, 0.0, 0.0, 0.0], [0.00017548352479934692, 0.00034485262585803866, 0.0011026483261957765, 0.00010296398249920458, 0.003907196223735809, 0.02227865532040596, 0.009483844973146915, 0.04698142781853676, 0.33048346638679504, 0.143778458237648, 0.44136106967926025, 0.0, 0.0, 0.0], [0.009998427703976631, 0.013220394030213356, 0.007993574254214764, 0.0018923792522400618, 0.005182519089430571, 0.05694546550512314, 0.02282009832561016, 0.028892531991004944, 0.11077435314655304, 0.37083950638771057, 0.33382436633110046, 0.03761632740497589, 0.0, 0.0], [0.00259813922457397, 0.003237744327634573, 0.005209536757320166, 0.0003279574739281088, 0.005902866367250681, 0.03494604676961899, 0.016762128099799156, 0.045891474932432175, 0.226464182138443, 0.2721498906612396, 0.360718697309494, 0.025791319087147713, 0.0, 0.0], [0.00311656785197556, 0.0037183884996920824, 0.005867836996912956, 0.00042606843635439873, 0.0076430123299360275, 0.0410926416516304, 0.02049352414906025, 0.05680950731039047, 0.23154622316360474, 0.2541244626045227, 0.34254780411720276, 0.03261397033929825, 0.0, 0.0]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9875233769416809, 0.012476620264351368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.485541433095932, 0.19370654225349426, 0.3207520544528961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002529261982999742, 0.0025948109105229378, 0.007045430596917868, 0.9901068210601807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04711448401212692, 0.08118678629398346, 0.0690288245677948, 0.1985442191362381, 0.6041256785392761, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0006890714867040515, 0.010935173369944096, 0.031793609261512756, 0.5145927667617798, 0.2034258097410202, 0.23856353759765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002406570129096508, 0.01726013794541359, 0.005073157604783773, 0.0813254863023758, 0.017954183742403984, 0.5861687064170837, 0.28981173038482666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014447244815528393, 0.004023877903819084, 0.002038016216829419, 0.005706000607460737, 0.008691845461726189, 0.6276112794876099, 0.2667316198348999, 0.0707501471042633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001884262077510357, 0.027516501024365425, 0.014214511960744858, 0.059111226350069046, 0.03682437539100647, 0.47988876700401306, 0.2138548195362091, 0.1146470382809639, 0.05205848067998886, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07479076832532883, 0.03223688527941704, 0.03586127981543541, 0.07819979637861252, 0.0497591495513916, 0.18349316716194153, 0.1661633402109146, 0.10191766172647476, 0.08688941597938538, 0.19068852066993713, 0.0, 0.0, 0.0, 0.0], [0.0007047628168947995, 0.0019432001281529665, 0.002579360967501998, 0.1564793884754181, 0.029092157259583473, 0.3581378757953644, 0.056700658053159714, 0.114737868309021, 0.04904633387923241, 0.033348217606544495, 0.19723019003868103, 0.0, 0.0, 0.0], [0.056802425533533096, 0.01083375047892332, 0.008767040446400642, 0.04346858710050583, 0.01920964941382408, 0.27897244691848755, 0.26162540912628174, 0.04866890609264374, 0.059157177805900574, 0.0488278791308403, 0.1058846265077591, 0.057782143354415894, 0.0, 0.0], [0.09352843463420868, 0.013499732129275799, 0.03737873584032059, 0.1491440385580063, 0.044102322310209274, 0.10966267436742783, 0.07534057646989822, 0.051040977239608765, 0.09814245998859406, 0.08842267841100693, 0.17193086445331573, 0.06780646741390228, 0.0, 0.0], [0.13973714411258698, 0.016634594649076462, 0.04265352338552475, 0.15283043682575226, 0.04103915020823479, 0.10301969200372696, 0.07098440825939178, 0.04781663417816162, 0.09785891324281693, 0.0759577751159668, 0.14794063568115234, 0.06352706998586655, 0.0, 0.0]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4879622757434845, 0.5120376944541931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.34392163157463074, 0.277255117893219, 0.37882325053215027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3858521282672882, 0.3516615629196167, 0.18308502435684204, 0.07940129190683365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05338314548134804, 0.07726400345563889, 0.15045058727264404, 0.47246959805488586, 0.24643263220787048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014817940071225166, 0.021870985627174377, 0.024950439110398293, 0.03205017000436783, 0.37795570492744446, 0.5283547639846802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.020682360976934433, 0.07747739553451538, 0.06969024240970612, 0.028273191303014755, 0.2017485648393631, 0.293379545211792, 0.30874866247177124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07908658683300018, 0.10550551861524582, 0.17829731106758118, 0.3312755823135376, 0.06761637330055237, 0.05020703375339508, 0.13099363446235657, 0.05701792612671852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06539306789636612, 0.09253942221403122, 0.15993772447109222, 0.052371274679899216, 0.08937112241983414, 0.04333066567778587, 0.11248946189880371, 0.12679004669189453, 0.2577771842479706, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08344480395317078, 0.14751769602298737, 0.25936853885650635, 0.1876228153705597, 0.048188671469688416, 0.024530120193958282, 0.0758870393037796, 0.04761888086795807, 0.07980655878782272, 0.04601486399769783, 0.0, 0.0, 0.0, 0.0], [0.07347460091114044, 0.1558298021554947, 0.20099198818206787, 0.10520495474338531, 0.040747493505477905, 0.020290914922952652, 0.049307066947221756, 0.0624699667096138, 0.13792073726654053, 0.06630420684814453, 0.08745827525854111, 0.0, 0.0, 0.0], [0.03799552842974663, 0.06289596110582352, 0.13348808884620667, 0.07766322046518326, 0.09828352928161621, 0.04316165670752525, 0.05240350216627121, 0.10779587179422379, 0.059943705797195435, 0.09275901317596436, 0.13005273044109344, 0.10355716943740845, 0.0, 0.0], [0.1438443958759308, 0.1957194209098816, 0.18213757872581482, 0.1478496491909027, 0.03500867262482643, 0.02275245077908039, 0.05189824476838112, 0.03143448382616043, 0.02707066759467125, 0.029966754838824272, 0.06653735786676407, 0.06578027456998825, 0.0, 0.0], [0.16702775657176971, 0.20165041089057922, 0.1581464260816574, 0.1561889350414276, 0.03385787457227707, 0.0230161901563406, 0.0493709035217762, 0.030397804453969002, 0.02702253870666027, 0.0295976921916008, 0.05761156976222992, 0.06611189246177673, 0.0, 0.0]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8873611092567444, 0.11263889074325562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11665301024913788, 0.6225963830947876, 0.2607506811618805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10163391381502151, 0.07281915098428726, 0.7497185468673706, 0.0758284330368042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13445760309696198, 0.04579111561179161, 0.4905867278575897, 0.19946202635765076, 0.12970256805419922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1347656399011612, 0.03032347932457924, 0.10070927441120148, 0.042643576860427856, 0.5924267172813416, 0.09913134574890137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10799223184585571, 0.0416230708360672, 0.05052386596798897, 0.09957215934991837, 0.2668352723121643, 0.1329466551542282, 0.30050674080848694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11830397695302963, 0.08327307552099228, 0.024222426116466522, 0.11059999465942383, 0.2772905230522156, 0.07615545392036438, 0.18388082087039948, 0.1262737661600113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06425895541906357, 0.07129554450511932, 0.010387292131781578, 0.07384678721427917, 0.08269906789064407, 0.12144017964601517, 0.12694965302944183, 0.365535169839859, 0.08358728885650635, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05659838020801544, 0.0054657780565321445, 0.08760195225477219, 0.053912561386823654, 0.14925014972686768, 0.06107267737388611, 0.20072081685066223, 0.1884745955467224, 0.1900682896375656, 0.00683479942381382, 0.0, 0.0, 0.0, 0.0], [0.004976694472134113, 0.005369553342461586, 0.034639984369277954, 0.008380139246582985, 0.009245160035789013, 0.014517738483846188, 0.01385078951716423, 0.054555874317884445, 0.020342005416750908, 0.17392531037330627, 0.660196840763092, 0.0, 0.0, 0.0], [0.005810907576233149, 0.005459466949105263, 0.06411834806203842, 0.016681544482707977, 0.008158880285918713, 0.020616523921489716, 0.007083709351718426, 0.015777001157402992, 0.0137746287509799, 0.031222878023982048, 0.6619716286659241, 0.14932435750961304, 0.0, 0.0], [0.01979498192667961, 0.015134822577238083, 0.015590719878673553, 0.02792835794389248, 0.07466865330934525, 0.03219024837017059, 0.08022361993789673, 0.12534257769584656, 0.1049802228808403, 0.03157804533839226, 0.31907305121421814, 0.153494730591774, 0.0, 0.0], [0.03267242759466171, 0.02926531434059143, 0.009621817618608475, 0.03327975049614906, 0.1160404235124588, 0.03887241706252098, 0.1386292427778244, 0.18638892471790314, 0.14293164014816284, 0.04003675654530525, 0.13218700885772705, 0.10007423162460327, 0.0, 0.0]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8458619117736816, 0.15413804352283478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21327728033065796, 0.46057382225990295, 0.3261488378047943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05355440452694893, 0.30790215730667114, 0.5454094409942627, 0.09313401579856873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5865398049354553, 0.04704765975475311, 0.0063453977927565575, 0.339293897151947, 0.020773204043507576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14127258956432343, 0.151571586728096, 0.23900197446346283, 0.0650983527302742, 0.29552778601646423, 0.1075277104973793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03810809552669525, 0.04348812252283096, 0.02057993970811367, 0.054202787578105927, 0.05007794499397278, 0.5950115323066711, 0.1985316127538681, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09487556666135788, 0.030793843790888786, 0.007549136411398649, 0.05803292244672775, 0.016673706471920013, 0.25746291875839233, 0.27702125906944275, 0.2575905919075012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06198638305068016, 0.17616493999958038, 0.13734401762485504, 0.07004618644714355, 0.08618349581956863, 0.24403756856918335, 0.0830104723572731, 0.07003597915172577, 0.0711909681558609, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07837406545877457, 0.01811295375227928, 0.17104394733905792, 0.09811647236347198, 0.13203833997249603, 0.0242551751434803, 0.03301931545138359, 0.027182184159755707, 0.40833747386932373, 0.009520014747977257, 0.0, 0.0, 0.0, 0.0], [0.003343193093314767, 0.03760922700166702, 0.0015596672892570496, 0.010382222011685371, 0.0034839599393308163, 0.07658960670232773, 0.09260181337594986, 0.0167407114058733, 0.23296555876731873, 0.2165765017271042, 0.30814749002456665, 0.0, 0.0, 0.0], [0.017645884305238724, 0.013284203596413136, 0.006944037973880768, 0.030848463997244835, 0.01587596908211708, 0.05411859229207039, 0.061732325702905655, 0.009138735942542553, 0.2912288010120392, 0.024853087961673737, 0.2964312732219696, 0.1778986155986786, 0.0, 0.0], [0.13910186290740967, 0.0873529314994812, 0.12295834720134735, 0.08039912581443787, 0.13134987652301788, 0.016787033528089523, 0.05717292055487633, 0.05309513956308365, 0.08697638660669327, 0.052101630717515945, 0.07249107956886292, 0.10021370649337769, 0.0, 0.0], [0.13351936638355255, 0.1465865522623062, 0.2063014656305313, 0.06428197771310806, 0.1520024538040161, 0.011169780977070332, 0.041457172483205795, 0.05575600638985634, 0.04284650832414627, 0.06906978785991669, 0.03132825344800949, 0.04568066820502281, 0.0, 0.0]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8306133151054382, 0.16938672959804535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22766287624835968, 0.5797580480575562, 0.19257909059524536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19908659160137177, 0.0923955962061882, 0.5311257839202881, 0.17739209532737732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.27059343457221985, 0.1640642136335373, 0.3321642577648163, 0.19827620685100555, 0.034901876002550125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07688752561807632, 0.03223097696900368, 0.05224015191197395, 0.1144498810172081, 0.683306872844696, 0.040884535759687424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05449414625763893, 0.25597289204597473, 0.08018738031387329, 0.022821027785539627, 0.16680657863616943, 0.21331988275051117, 0.20639806985855103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0910809338092804, 0.35657432675361633, 0.08306941390037537, 0.013706418685615063, 0.04256729036569595, 0.14280468225479126, 0.14901338517665863, 0.12118355184793472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05748032033443451, 0.523878812789917, 0.10376811027526855, 0.003998319152742624, 0.04377935081720352, 0.0909801498055458, 0.038367535918951035, 0.11760774999856949, 0.020139604806900024, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01369933970272541, 0.0032544522546231747, 0.0008398143108934164, 0.6631109714508057, 0.02997838333249092, 0.010082428343594074, 0.15333148837089539, 0.00790861714631319, 0.11572305858135223, 0.0020714353304356337, 0.0, 0.0, 0.0, 0.0], [0.01275063306093216, 0.031128598377108574, 0.0073225488886237144, 0.058021146804094315, 0.03595747798681259, 0.006297598127275705, 0.11066271364688873, 0.037936192005872726, 0.026497358456254005, 0.19652549922466278, 0.4769001603126526, 0.0, 0.0, 0.0], [0.014500297605991364, 0.008086043410003185, 0.004964529071003199, 0.13091810047626495, 0.026806144043803215, 0.01049333531409502, 0.10739143937826157, 0.016854867339134216, 0.04340110346674919, 0.025324536487460136, 0.4955841898918152, 0.1156754121184349, 0.0, 0.0], [0.04465939477086067, 0.019342608749866486, 0.009600576013326645, 0.3816627264022827, 0.041847631335258484, 0.026093047112226486, 0.05961070954799652, 0.02126859501004219, 0.07055836170911789, 0.017030959948897362, 0.22898882627487183, 0.0793364942073822, 0.0, 0.0], [0.07036981731653214, 0.06461331248283386, 0.014665143564343452, 0.20816200971603394, 0.06113061308860779, 0.04915817454457283, 0.0508684441447258, 0.035715315490961075, 0.09668688476085663, 0.05588753893971443, 0.21010035276412964, 0.08264244347810745, 0.0, 0.0]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7072598934173584, 0.2927401065826416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2321942299604416, 0.7523769736289978, 0.015428819693624973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19062180817127228, 0.0643564835190773, 0.7046249508857727, 0.04039676487445831, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3544122576713562, 0.15764302015304565, 0.13778209686279297, 0.22285684943199158, 0.1273057907819748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1997859925031662, 0.26555031538009644, 0.03974050655961037, 0.10300124436616898, 0.1546584516763687, 0.2372635155916214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1261366754770279, 0.05141695588827133, 0.20563822984695435, 0.06175386533141136, 0.12788927555084229, 0.373463898897171, 0.053701043128967285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07557777315378189, 0.1604347825050354, 0.013816900551319122, 0.22591795027256012, 0.09903332591056824, 0.035298630595207214, 0.330075740814209, 0.05984489992260933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10766152292490005, 0.02698725275695324, 0.35764509439468384, 0.077109195291996, 0.10332969576120377, 0.20676399767398834, 0.014517443254590034, 0.07311281561851501, 0.032873015850782394, 0.0, 0.0, 0.0, 0.0, 0.0], [0.069455586373806, 0.08698386698961258, 0.008149717003107071, 0.1873944252729416, 0.07525302469730377, 0.04461194574832916, 0.18574321269989014, 0.17492139339447021, 0.06530890613794327, 0.1021779254078865, 0.0, 0.0, 0.0, 0.0], [0.02491864003241062, 0.009469747543334961, 0.010675852186977863, 0.0736108124256134, 0.03652241453528404, 0.0785205289721489, 0.026960859075188637, 0.06388247013092041, 0.02780783176422119, 0.056484851986169815, 0.5911459922790527, 0.0, 0.0, 0.0], [0.024866966530680656, 0.01632085256278515, 0.011620230972766876, 0.07994507253170013, 0.0525670200586319, 0.0705929547548294, 0.024858325719833374, 0.04453077167272568, 0.029579883441329002, 0.09183569252490997, 0.38658156991004944, 0.1667005866765976, 0.0, 0.0], [0.028856750577688217, 0.026154937222599983, 0.010065490379929543, 0.16581633687019348, 0.06276494264602661, 0.0439431369304657, 0.05753815174102783, 0.06746510416269302, 0.024168869480490685, 0.09067010134458542, 0.26605454087257385, 0.15650160610675812, 0.0, 0.0], [0.03228337690234184, 0.03487921878695488, 0.023571802303195, 0.16175991296768188, 0.07788614183664322, 0.05282926559448242, 0.048157986253499985, 0.05506175756454468, 0.025465460494160652, 0.06388898193836212, 0.2736394703388214, 0.1505766659975052, 0.0, 0.0]]]], \"left_text\": [\"<BOS>\", \"f\", \"l\", \"y\", \"c\", \"a\", \"t\", \"c\", \"h\", \"e\", \"r\", \"<EOS>\", \"<PAD>\", \"<PAD>\"], \"right_text\": [\"<BOS>\", \"f\", \"l\", \"y\", \"c\", \"a\", \"t\", \"c\", \"h\", \"e\", \"r\", \"<EOS>\", \"<PAD>\", \"<PAD>\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-4e8a4e4f170e4d00b535b768f480fdfe\", \"layer\": null, \"heads\": null, \"include_layers\": [0, 1]}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.724626898765564, 0.27537307143211365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1684461236000061, 0.1115279570221901, 0.720025897026062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.029132423922419548, 0.04113442823290825, 0.9009055495262146, 0.028827643021941185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010972388088703156, 0.008973889984190464, 0.040146831423044205, 0.036990247666835785, 0.9029166102409363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004904638044536114, 0.0013782645110040903, 0.005036907270550728, 0.008212740533053875, 0.2641729414463043, 0.7207086682319641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0009746559080667794, 0.0008959718397818506, 0.0021742319222539663, 0.00540682440623641, 0.06183263659477234, 0.39220893383026123, 0.5365068316459656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002428296720609069, 0.0015334871131926775, 0.003229082329198718, 0.0035730230156332254, 0.021443935111165047, 0.5649051070213318, 0.23574990034103394, 0.16713713109493256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005359534174203873, 0.008710755035281181, 0.015554056502878666, 0.020073745399713516, 0.06700840592384338, 0.14202512800693512, 0.18731273710727692, 0.18625080585479736, 0.367704838514328, 0.0, 0.0, 0.0, 0.0, 0.0], [8.504252036800608e-05, 0.00023528042947873473, 0.0006260576192289591, 0.0007276212563738227, 0.005674776155501604, 0.0417969711124897, 0.08456667512655258, 0.04192569851875305, 0.1542774885892868, 0.6700844764709473, 0.0, 0.0, 0.0, 0.0], [3.647639096016064e-05, 0.00011635245755314827, 0.00026732328115031123, 0.0003926251665689051, 0.003144270973280072, 0.04079451784491539, 0.07613306492567062, 0.03364671766757965, 0.1715421825647354, 0.39352843165397644, 0.28039810061454773, 0.0, 0.0, 0.0], [0.032451849430799484, 0.017949745059013367, 0.01732417196035385, 0.05450862646102905, 0.059766724705696106, 0.12705129384994507, 0.15503446757793427, 0.08913806080818176, 0.15542979538440704, 0.08211970329284668, 0.13604171574115753, 0.0731838271021843, 0.0, 0.0], [0.027014754712581635, 0.03181717172265053, 0.034102752804756165, 0.01801958680152893, 0.012956619262695312, 0.07816128432750702, 0.04855794459581375, 0.026575841009616852, 0.15788380801677704, 0.14508014917373657, 0.3689577281475067, 0.05087234079837799, 0.0, 0.0], [0.04780331999063492, 0.04679042100906372, 0.048802100121974945, 0.022626640275120735, 0.01604725793004036, 0.08953594416379929, 0.043370943516492844, 0.02934807352721691, 0.15936627984046936, 0.12515224516391754, 0.32143649458885193, 0.04972030967473984, 0.0, 0.0]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4110870063304901, 0.5889129638671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16972269117832184, 0.20270906388759613, 0.627568244934082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08933189511299133, 0.09739500284194946, 0.7171462774276733, 0.0961267352104187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08247150480747223, 0.12218286842107773, 0.2283076047897339, 0.11560782045125961, 0.45143020153045654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05360184609889984, 0.04008046165108681, 0.1287464201450348, 0.08797754347324371, 0.44119247794151306, 0.2484012395143509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.039485689252614975, 0.03861238807439804, 0.03143446147441864, 0.0211022961884737, 0.09542834013700485, 0.5101359486579895, 0.2638009488582611, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.026426047086715698, 0.0228985957801342, 0.04010944813489914, 0.014966877177357674, 0.06548593938350677, 0.3337010443210602, 0.1271722912788391, 0.3692397177219391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03793273866176605, 0.026227010414004326, 0.041103705763816833, 0.004962393082678318, 0.021144136786460876, 0.12746919691562653, 0.04975343868136406, 0.12392136454582214, 0.5674859285354614, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00402842229232192, 0.0037421416491270065, 0.013327698223292828, 0.0010023198556154966, 0.022974679246544838, 0.0294973012059927, 0.05279850587248802, 0.11170019209384918, 0.4291641116142273, 0.33176469802856445, 0.0, 0.0, 0.0, 0.0], [0.00017548352479934692, 0.00034485262585803866, 0.0011026483261957765, 0.00010296398249920458, 0.003907196223735809, 0.02227865532040596, 0.009483844973146915, 0.04698142781853676, 0.33048346638679504, 0.143778458237648, 0.44136106967926025, 0.0, 0.0, 0.0], [0.009998427703976631, 0.013220394030213356, 0.007993574254214764, 0.0018923792522400618, 0.005182519089430571, 0.05694546550512314, 0.02282009832561016, 0.028892531991004944, 0.11077435314655304, 0.37083950638771057, 0.33382436633110046, 0.03761632740497589, 0.0, 0.0], [0.00259813922457397, 0.003237744327634573, 0.005209536757320166, 0.0003279574739281088, 0.005902866367250681, 0.03494604676961899, 0.016762128099799156, 0.045891474932432175, 0.226464182138443, 0.2721498906612396, 0.360718697309494, 0.025791319087147713, 0.0, 0.0], [0.00311656785197556, 0.0037183884996920824, 0.005867836996912956, 0.00042606843635439873, 0.0076430123299360275, 0.0410926416516304, 0.02049352414906025, 0.05680950731039047, 0.23154622316360474, 0.2541244626045227, 0.34254780411720276, 0.03261397033929825, 0.0, 0.0]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9875233769416809, 0.012476620264351368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.485541433095932, 0.19370654225349426, 0.3207520544528961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002529261982999742, 0.0025948109105229378, 0.007045430596917868, 0.9901068210601807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04711448401212692, 0.08118678629398346, 0.0690288245677948, 0.1985442191362381, 0.6041256785392761, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0006890714867040515, 0.010935173369944096, 0.031793609261512756, 0.5145927667617798, 0.2034258097410202, 0.23856353759765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002406570129096508, 0.01726013794541359, 0.005073157604783773, 0.0813254863023758, 0.017954183742403984, 0.5861687064170837, 0.28981173038482666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014447244815528393, 0.004023877903819084, 0.002038016216829419, 0.005706000607460737, 0.008691845461726189, 0.6276112794876099, 0.2667316198348999, 0.0707501471042633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001884262077510357, 0.027516501024365425, 0.014214511960744858, 0.059111226350069046, 0.03682437539100647, 0.47988876700401306, 0.2138548195362091, 0.1146470382809639, 0.05205848067998886, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07479076832532883, 0.03223688527941704, 0.03586127981543541, 0.07819979637861252, 0.0497591495513916, 0.18349316716194153, 0.1661633402109146, 0.10191766172647476, 0.08688941597938538, 0.19068852066993713, 0.0, 0.0, 0.0, 0.0], [0.0007047628168947995, 0.0019432001281529665, 0.002579360967501998, 0.1564793884754181, 0.029092157259583473, 0.3581378757953644, 0.056700658053159714, 0.114737868309021, 0.04904633387923241, 0.033348217606544495, 0.19723019003868103, 0.0, 0.0, 0.0], [0.056802425533533096, 0.01083375047892332, 0.008767040446400642, 0.04346858710050583, 0.01920964941382408, 0.27897244691848755, 0.26162540912628174, 0.04866890609264374, 0.059157177805900574, 0.0488278791308403, 0.1058846265077591, 0.057782143354415894, 0.0, 0.0], [0.09352843463420868, 0.013499732129275799, 0.03737873584032059, 0.1491440385580063, 0.044102322310209274, 0.10966267436742783, 0.07534057646989822, 0.051040977239608765, 0.09814245998859406, 0.08842267841100693, 0.17193086445331573, 0.06780646741390228, 0.0, 0.0], [0.13973714411258698, 0.016634594649076462, 0.04265352338552475, 0.15283043682575226, 0.04103915020823479, 0.10301969200372696, 0.07098440825939178, 0.04781663417816162, 0.09785891324281693, 0.0759577751159668, 0.14794063568115234, 0.06352706998586655, 0.0, 0.0]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4879622757434845, 0.5120376944541931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.34392163157463074, 0.277255117893219, 0.37882325053215027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3858521282672882, 0.3516615629196167, 0.18308502435684204, 0.07940129190683365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05338314548134804, 0.07726400345563889, 0.15045058727264404, 0.47246959805488586, 0.24643263220787048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014817940071225166, 0.021870985627174377, 0.024950439110398293, 0.03205017000436783, 0.37795570492744446, 0.5283547639846802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.020682360976934433, 0.07747739553451538, 0.06969024240970612, 0.028273191303014755, 0.2017485648393631, 0.293379545211792, 0.30874866247177124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07908658683300018, 0.10550551861524582, 0.17829731106758118, 0.3312755823135376, 0.06761637330055237, 0.05020703375339508, 0.13099363446235657, 0.05701792612671852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06539306789636612, 0.09253942221403122, 0.15993772447109222, 0.052371274679899216, 0.08937112241983414, 0.04333066567778587, 0.11248946189880371, 0.12679004669189453, 0.2577771842479706, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08344480395317078, 0.14751769602298737, 0.25936853885650635, 0.1876228153705597, 0.048188671469688416, 0.024530120193958282, 0.0758870393037796, 0.04761888086795807, 0.07980655878782272, 0.04601486399769783, 0.0, 0.0, 0.0, 0.0], [0.07347460091114044, 0.1558298021554947, 0.20099198818206787, 0.10520495474338531, 0.040747493505477905, 0.020290914922952652, 0.049307066947221756, 0.0624699667096138, 0.13792073726654053, 0.06630420684814453, 0.08745827525854111, 0.0, 0.0, 0.0], [0.03799552842974663, 0.06289596110582352, 0.13348808884620667, 0.07766322046518326, 0.09828352928161621, 0.04316165670752525, 0.05240350216627121, 0.10779587179422379, 0.059943705797195435, 0.09275901317596436, 0.13005273044109344, 0.10355716943740845, 0.0, 0.0], [0.1438443958759308, 0.1957194209098816, 0.18213757872581482, 0.1478496491909027, 0.03500867262482643, 0.02275245077908039, 0.05189824476838112, 0.03143448382616043, 0.02707066759467125, 0.029966754838824272, 0.06653735786676407, 0.06578027456998825, 0.0, 0.0], [0.16702775657176971, 0.20165041089057922, 0.1581464260816574, 0.1561889350414276, 0.03385787457227707, 0.0230161901563406, 0.0493709035217762, 0.030397804453969002, 0.02702253870666027, 0.0295976921916008, 0.05761156976222992, 0.06611189246177673, 0.0, 0.0]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8873611092567444, 0.11263889074325562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11665301024913788, 0.6225963830947876, 0.2607506811618805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10163391381502151, 0.07281915098428726, 0.7497185468673706, 0.0758284330368042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13445760309696198, 0.04579111561179161, 0.4905867278575897, 0.19946202635765076, 0.12970256805419922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1347656399011612, 0.03032347932457924, 0.10070927441120148, 0.042643576860427856, 0.5924267172813416, 0.09913134574890137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10799223184585571, 0.0416230708360672, 0.05052386596798897, 0.09957215934991837, 0.2668352723121643, 0.1329466551542282, 0.30050674080848694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11830397695302963, 0.08327307552099228, 0.024222426116466522, 0.11059999465942383, 0.2772905230522156, 0.07615545392036438, 0.18388082087039948, 0.1262737661600113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06425895541906357, 0.07129554450511932, 0.010387292131781578, 0.07384678721427917, 0.08269906789064407, 0.12144017964601517, 0.12694965302944183, 0.365535169839859, 0.08358728885650635, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05659838020801544, 0.0054657780565321445, 0.08760195225477219, 0.053912561386823654, 0.14925014972686768, 0.06107267737388611, 0.20072081685066223, 0.1884745955467224, 0.1900682896375656, 0.00683479942381382, 0.0, 0.0, 0.0, 0.0], [0.004976694472134113, 0.005369553342461586, 0.034639984369277954, 0.008380139246582985, 0.009245160035789013, 0.014517738483846188, 0.01385078951716423, 0.054555874317884445, 0.020342005416750908, 0.17392531037330627, 0.660196840763092, 0.0, 0.0, 0.0], [0.005810907576233149, 0.005459466949105263, 0.06411834806203842, 0.016681544482707977, 0.008158880285918713, 0.020616523921489716, 0.007083709351718426, 0.015777001157402992, 0.0137746287509799, 0.031222878023982048, 0.6619716286659241, 0.14932435750961304, 0.0, 0.0], [0.01979498192667961, 0.015134822577238083, 0.015590719878673553, 0.02792835794389248, 0.07466865330934525, 0.03219024837017059, 0.08022361993789673, 0.12534257769584656, 0.1049802228808403, 0.03157804533839226, 0.31907305121421814, 0.153494730591774, 0.0, 0.0], [0.03267242759466171, 0.02926531434059143, 0.009621817618608475, 0.03327975049614906, 0.1160404235124588, 0.03887241706252098, 0.1386292427778244, 0.18638892471790314, 0.14293164014816284, 0.04003675654530525, 0.13218700885772705, 0.10007423162460327, 0.0, 0.0]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8458619117736816, 0.15413804352283478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21327728033065796, 0.46057382225990295, 0.3261488378047943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05355440452694893, 0.30790215730667114, 0.5454094409942627, 0.09313401579856873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5865398049354553, 0.04704765975475311, 0.0063453977927565575, 0.339293897151947, 0.020773204043507576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14127258956432343, 0.151571586728096, 0.23900197446346283, 0.0650983527302742, 0.29552778601646423, 0.1075277104973793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03810809552669525, 0.04348812252283096, 0.02057993970811367, 0.054202787578105927, 0.05007794499397278, 0.5950115323066711, 0.1985316127538681, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09487556666135788, 0.030793843790888786, 0.007549136411398649, 0.05803292244672775, 0.016673706471920013, 0.25746291875839233, 0.27702125906944275, 0.2575905919075012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06198638305068016, 0.17616493999958038, 0.13734401762485504, 0.07004618644714355, 0.08618349581956863, 0.24403756856918335, 0.0830104723572731, 0.07003597915172577, 0.0711909681558609, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07837406545877457, 0.01811295375227928, 0.17104394733905792, 0.09811647236347198, 0.13203833997249603, 0.0242551751434803, 0.03301931545138359, 0.027182184159755707, 0.40833747386932373, 0.009520014747977257, 0.0, 0.0, 0.0, 0.0], [0.003343193093314767, 0.03760922700166702, 0.0015596672892570496, 0.010382222011685371, 0.0034839599393308163, 0.07658960670232773, 0.09260181337594986, 0.0167407114058733, 0.23296555876731873, 0.2165765017271042, 0.30814749002456665, 0.0, 0.0, 0.0], [0.017645884305238724, 0.013284203596413136, 0.006944037973880768, 0.030848463997244835, 0.01587596908211708, 0.05411859229207039, 0.061732325702905655, 0.009138735942542553, 0.2912288010120392, 0.024853087961673737, 0.2964312732219696, 0.1778986155986786, 0.0, 0.0], [0.13910186290740967, 0.0873529314994812, 0.12295834720134735, 0.08039912581443787, 0.13134987652301788, 0.016787033528089523, 0.05717292055487633, 0.05309513956308365, 0.08697638660669327, 0.052101630717515945, 0.07249107956886292, 0.10021370649337769, 0.0, 0.0], [0.13351936638355255, 0.1465865522623062, 0.2063014656305313, 0.06428197771310806, 0.1520024538040161, 0.011169780977070332, 0.041457172483205795, 0.05575600638985634, 0.04284650832414627, 0.06906978785991669, 0.03132825344800949, 0.04568066820502281, 0.0, 0.0]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8306133151054382, 0.16938672959804535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22766287624835968, 0.5797580480575562, 0.19257909059524536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19908659160137177, 0.0923955962061882, 0.5311257839202881, 0.17739209532737732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.27059343457221985, 0.1640642136335373, 0.3321642577648163, 0.19827620685100555, 0.034901876002550125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07688752561807632, 0.03223097696900368, 0.05224015191197395, 0.1144498810172081, 0.683306872844696, 0.040884535759687424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05449414625763893, 0.25597289204597473, 0.08018738031387329, 0.022821027785539627, 0.16680657863616943, 0.21331988275051117, 0.20639806985855103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0910809338092804, 0.35657432675361633, 0.08306941390037537, 0.013706418685615063, 0.04256729036569595, 0.14280468225479126, 0.14901338517665863, 0.12118355184793472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05748032033443451, 0.523878812789917, 0.10376811027526855, 0.003998319152742624, 0.04377935081720352, 0.0909801498055458, 0.038367535918951035, 0.11760774999856949, 0.020139604806900024, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01369933970272541, 0.0032544522546231747, 0.0008398143108934164, 0.6631109714508057, 0.02997838333249092, 0.010082428343594074, 0.15333148837089539, 0.00790861714631319, 0.11572305858135223, 0.0020714353304356337, 0.0, 0.0, 0.0, 0.0], [0.01275063306093216, 0.031128598377108574, 0.0073225488886237144, 0.058021146804094315, 0.03595747798681259, 0.006297598127275705, 0.11066271364688873, 0.037936192005872726, 0.026497358456254005, 0.19652549922466278, 0.4769001603126526, 0.0, 0.0, 0.0], [0.014500297605991364, 0.008086043410003185, 0.004964529071003199, 0.13091810047626495, 0.026806144043803215, 0.01049333531409502, 0.10739143937826157, 0.016854867339134216, 0.04340110346674919, 0.025324536487460136, 0.4955841898918152, 0.1156754121184349, 0.0, 0.0], [0.04465939477086067, 0.019342608749866486, 0.009600576013326645, 0.3816627264022827, 0.041847631335258484, 0.026093047112226486, 0.05961070954799652, 0.02126859501004219, 0.07055836170911789, 0.017030959948897362, 0.22898882627487183, 0.0793364942073822, 0.0, 0.0], [0.07036981731653214, 0.06461331248283386, 0.014665143564343452, 0.20816200971603394, 0.06113061308860779, 0.04915817454457283, 0.0508684441447258, 0.035715315490961075, 0.09668688476085663, 0.05588753893971443, 0.21010035276412964, 0.08264244347810745, 0.0, 0.0]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7072598934173584, 0.2927401065826416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2321942299604416, 0.7523769736289978, 0.015428819693624973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19062180817127228, 0.0643564835190773, 0.7046249508857727, 0.04039676487445831, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3544122576713562, 0.15764302015304565, 0.13778209686279297, 0.22285684943199158, 0.1273057907819748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1997859925031662, 0.26555031538009644, 0.03974050655961037, 0.10300124436616898, 0.1546584516763687, 0.2372635155916214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1261366754770279, 0.05141695588827133, 0.20563822984695435, 0.06175386533141136, 0.12788927555084229, 0.373463898897171, 0.053701043128967285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07557777315378189, 0.1604347825050354, 0.013816900551319122, 0.22591795027256012, 0.09903332591056824, 0.035298630595207214, 0.330075740814209, 0.05984489992260933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10766152292490005, 0.02698725275695324, 0.35764509439468384, 0.077109195291996, 0.10332969576120377, 0.20676399767398834, 0.014517443254590034, 0.07311281561851501, 0.032873015850782394, 0.0, 0.0, 0.0, 0.0, 0.0], [0.069455586373806, 0.08698386698961258, 0.008149717003107071, 0.1873944252729416, 0.07525302469730377, 0.04461194574832916, 0.18574321269989014, 0.17492139339447021, 0.06530890613794327, 0.1021779254078865, 0.0, 0.0, 0.0, 0.0], [0.02491864003241062, 0.009469747543334961, 0.010675852186977863, 0.0736108124256134, 0.03652241453528404, 0.0785205289721489, 0.026960859075188637, 0.06388247013092041, 0.02780783176422119, 0.056484851986169815, 0.5911459922790527, 0.0, 0.0, 0.0], [0.024866966530680656, 0.01632085256278515, 0.011620230972766876, 0.07994507253170013, 0.0525670200586319, 0.0705929547548294, 0.024858325719833374, 0.04453077167272568, 0.029579883441329002, 0.09183569252490997, 0.38658156991004944, 0.1667005866765976, 0.0, 0.0], [0.028856750577688217, 0.026154937222599983, 0.010065490379929543, 0.16581633687019348, 0.06276494264602661, 0.0439431369304657, 0.05753815174102783, 0.06746510416269302, 0.024168869480490685, 0.09067010134458542, 0.26605454087257385, 0.15650160610675812, 0.0, 0.0], [0.03228337690234184, 0.03487921878695488, 0.023571802303195, 0.16175991296768188, 0.07788614183664322, 0.05282926559448242, 0.048157986253499985, 0.05506175756454468, 0.025465460494160652, 0.06388898193836212, 0.2736394703388214, 0.1505766659975052, 0.0, 0.0]]]], \"left_text\": [\"<BOS>\", \"f\", \"l\", \"y\", \"c\", \"a\", \"t\", \"c\", \"h\", \"e\", \"r\", \"<EOS>\", \"<PAD>\", \"<PAD>\"], \"right_text\": [\"<BOS>\", \"f\", \"l\", \"y\", \"c\", \"a\", \"t\", \"c\", \"h\", \"e\", \"r\", \"<EOS>\", \"<PAD>\", \"<PAD>\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-4e8a4e4f170e4d00b535b768f480fdfe\", \"layer\": null, \"heads\": null, \"include_layers\": [0, 1]} is a template marker that is replaced by actual params.\n",
       "    const TEXT_SIZE = 15;\n",
       "    const BOXWIDTH = 110;\n",
       "    const BOXHEIGHT = 22.5;\n",
       "    const MATRIX_WIDTH = 115;\n",
       "    const CHECKBOX_SIZE = 20;\n",
       "    const TEXT_TOP = 30;\n",
       "\n",
       "    console.log(\"d3 version\", d3.version)\n",
       "    let headColors;\n",
       "    try {\n",
       "        headColors = d3.scaleOrdinal(d3.schemeCategory10);\n",
       "    } catch (err) {\n",
       "        console.log('Older d3 version')\n",
       "        headColors = d3.scale.category10();\n",
       "    }\n",
       "    let config = {};\n",
       "    initialize();\n",
       "    renderVis();\n",
       "\n",
       "    function initialize() {\n",
       "        config.attention = params['attention'];\n",
       "        config.filter = params['default_filter'];\n",
       "        config.rootDivId = params['root_div_id'];\n",
       "        config.nLayers = config.attention[config.filter]['attn'].length;\n",
       "        config.nHeads = config.attention[config.filter]['attn'][0].length;\n",
       "        config.layers = params['include_layers']\n",
       "\n",
       "        if (params['heads']) {\n",
       "            config.headVis = new Array(config.nHeads).fill(false);\n",
       "            params['heads'].forEach(x => config.headVis[x] = true);\n",
       "        } else {\n",
       "            config.headVis = new Array(config.nHeads).fill(true);\n",
       "        }\n",
       "        config.initialTextLength = config.attention[config.filter].right_text.length;\n",
       "        config.layer_seq = (params['layer'] == null ? 0 : config.layers.findIndex(layer => params['layer'] === layer));\n",
       "        config.layer = config.layers[config.layer_seq]\n",
       "\n",
       "        let layerEl = $(`#${config.rootDivId} #layer`);\n",
       "        for (const layer of config.layers) {\n",
       "            layerEl.append($(\"<option />\").val(layer).text(layer));\n",
       "        }\n",
       "        layerEl.val(config.layer).change();\n",
       "        layerEl.on('change', function (e) {\n",
       "            config.layer = +e.currentTarget.value;\n",
       "            config.layer_seq = config.layers.findIndex(layer => config.layer === layer);\n",
       "            renderVis();\n",
       "        });\n",
       "\n",
       "        $(`#${config.rootDivId} #filter`).on('change', function (e) {\n",
       "            config.filter = e.currentTarget.value;\n",
       "            renderVis();\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function renderVis() {\n",
       "\n",
       "        // Load parameters\n",
       "        const attnData = config.attention[config.filter];\n",
       "        const leftText = attnData.left_text;\n",
       "        const rightText = attnData.right_text;\n",
       "\n",
       "        // Select attention for given layer\n",
       "        const layerAttention = attnData.attn[config.layer_seq];\n",
       "\n",
       "        // Clear vis\n",
       "        $(`#${config.rootDivId} #vis`).empty();\n",
       "\n",
       "        // Determine size of visualization\n",
       "        const height = Math.max(leftText.length, rightText.length) * BOXHEIGHT + TEXT_TOP;\n",
       "        const svg = d3.select(`#${config.rootDivId} #vis`)\n",
       "            .append('svg')\n",
       "            .attr(\"width\", \"100%\")\n",
       "            .attr(\"height\", height + \"px\");\n",
       "\n",
       "        // Display tokens on left and right side of visualization\n",
       "        renderText(svg, leftText, true, layerAttention, 0);\n",
       "        renderText(svg, rightText, false, layerAttention, MATRIX_WIDTH + BOXWIDTH);\n",
       "\n",
       "        // Render attention arcs\n",
       "        renderAttention(svg, layerAttention);\n",
       "\n",
       "        // Draw squares at top of visualization, one for each head\n",
       "        drawCheckboxes(0, svg, layerAttention);\n",
       "    }\n",
       "\n",
       "    function renderText(svg, text, isLeft, attention, leftPos) {\n",
       "\n",
       "        const textContainer = svg.append(\"svg:g\")\n",
       "            .attr(\"id\", isLeft ? \"left\" : \"right\");\n",
       "\n",
       "        // Add attention highlights superimposed over words\n",
       "        textContainer.append(\"g\")\n",
       "            .classed(\"attentionBoxes\", true)\n",
       "            .selectAll(\"g\")\n",
       "            .data(attention)\n",
       "            .enter()\n",
       "            .append(\"g\")\n",
       "            .attr(\"head-index\", (d, i) => i)\n",
       "            .selectAll(\"rect\")\n",
       "            .data(d => isLeft ? d : transpose(d)) // if right text, transpose attention to get right-to-left weights\n",
       "            .enter()\n",
       "            .append(\"rect\")\n",
       "            .attr(\"x\", function () {\n",
       "                var headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
       "                return leftPos + boxOffsets(headIndex);\n",
       "            })\n",
       "            .attr(\"y\", (+1) * BOXHEIGHT)\n",
       "            .attr(\"width\", BOXWIDTH / activeHeads())\n",
       "            .attr(\"height\", BOXHEIGHT)\n",
       "            .attr(\"fill\", function () {\n",
       "                return headColors(+this.parentNode.getAttribute(\"head-index\"))\n",
       "            })\n",
       "            .style(\"opacity\", 0.0);\n",
       "\n",
       "        const tokenContainer = textContainer.append(\"g\").selectAll(\"g\")\n",
       "            .data(text)\n",
       "            .enter()\n",
       "            .append(\"g\");\n",
       "\n",
       "        // Add gray background that appears when hovering over text\n",
       "        tokenContainer.append(\"rect\")\n",
       "            .classed(\"background\", true)\n",
       "            .style(\"opacity\", 0.0)\n",
       "            .attr(\"fill\", \"lightgray\")\n",
       "            .attr(\"x\", leftPos)\n",
       "            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n",
       "            .attr(\"width\", BOXWIDTH)\n",
       "            .attr(\"height\", BOXHEIGHT);\n",
       "\n",
       "        // Add token text\n",
       "        const textEl = tokenContainer.append(\"text\")\n",
       "            .text(d => d)\n",
       "            .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "            .style(\"cursor\", \"default\")\n",
       "            .style(\"-webkit-user-select\", \"none\")\n",
       "            .attr(\"x\", leftPos)\n",
       "            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT);\n",
       "\n",
       "        if (isLeft) {\n",
       "            textEl.style(\"text-anchor\", \"end\")\n",
       "                .attr(\"dx\", BOXWIDTH - 0.5 * TEXT_SIZE)\n",
       "                .attr(\"dy\", TEXT_SIZE);\n",
       "        } else {\n",
       "            textEl.style(\"text-anchor\", \"start\")\n",
       "                .attr(\"dx\", +0.5 * TEXT_SIZE)\n",
       "                .attr(\"dy\", TEXT_SIZE);\n",
       "        }\n",
       "\n",
       "        tokenContainer.on(\"mouseover\", function (d, index) {\n",
       "\n",
       "            // Show gray background for moused-over token\n",
       "            textContainer.selectAll(\".background\")\n",
       "                .style(\"opacity\", (d, i) => i === index ? 1.0 : 0.0)\n",
       "\n",
       "            // Reset visibility attribute for any previously highlighted attention arcs\n",
       "            svg.select(\"#attention\")\n",
       "                .selectAll(\"line[visibility='visible']\")\n",
       "                .attr(\"visibility\", null)\n",
       "\n",
       "            // Hide group containing attention arcs\n",
       "            svg.select(\"#attention\").attr(\"visibility\", \"hidden\");\n",
       "\n",
       "            // Set to visible appropriate attention arcs to be highlighted\n",
       "            if (isLeft) {\n",
       "                svg.select(\"#attention\").selectAll(\"line[left-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n",
       "            } else {\n",
       "                svg.select(\"#attention\").selectAll(\"line[right-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n",
       "            }\n",
       "\n",
       "            // Update color boxes superimposed over tokens\n",
       "            const id = isLeft ? \"right\" : \"left\";\n",
       "            const leftPos = isLeft ? MATRIX_WIDTH + BOXWIDTH : 0;\n",
       "            svg.select(\"#\" + id)\n",
       "                .selectAll(\".attentionBoxes\")\n",
       "                .selectAll(\"g\")\n",
       "                .attr(\"head-index\", (d, i) => i)\n",
       "                .selectAll(\"rect\")\n",
       "                .attr(\"x\", function () {\n",
       "                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
       "                    return leftPos + boxOffsets(headIndex);\n",
       "                })\n",
       "                .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n",
       "                .attr(\"width\", BOXWIDTH / activeHeads())\n",
       "                .attr(\"height\", BOXHEIGHT)\n",
       "                .style(\"opacity\", function (d) {\n",
       "                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
       "                    if (config.headVis[headIndex])\n",
       "                        if (d) {\n",
       "                            return d[index];\n",
       "                        } else {\n",
       "                            return 0.0;\n",
       "                        }\n",
       "                    else\n",
       "                        return 0.0;\n",
       "                });\n",
       "        });\n",
       "\n",
       "        textContainer.on(\"mouseleave\", function () {\n",
       "\n",
       "            // Unhighlight selected token\n",
       "            d3.select(this).selectAll(\".background\")\n",
       "                .style(\"opacity\", 0.0);\n",
       "\n",
       "            // Reset visibility attributes for previously selected lines\n",
       "            svg.select(\"#attention\")\n",
       "                .selectAll(\"line[visibility='visible']\")\n",
       "                .attr(\"visibility\", null) ;\n",
       "            svg.select(\"#attention\").attr(\"visibility\", \"visible\");\n",
       "\n",
       "            // Reset highlights superimposed over tokens\n",
       "            svg.selectAll(\".attentionBoxes\")\n",
       "                .selectAll(\"g\")\n",
       "                .selectAll(\"rect\")\n",
       "                .style(\"opacity\", 0.0);\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function renderAttention(svg, attention) {\n",
       "\n",
       "        // Remove previous dom elements\n",
       "        svg.select(\"#attention\").remove();\n",
       "\n",
       "        // Add new elements\n",
       "        svg.append(\"g\")\n",
       "            .attr(\"id\", \"attention\") // Container for all attention arcs\n",
       "            .selectAll(\".headAttention\")\n",
       "            .data(attention)\n",
       "            .enter()\n",
       "            .append(\"g\")\n",
       "            .classed(\"headAttention\", true) // Group attention arcs by head\n",
       "            .attr(\"head-index\", (d, i) => i)\n",
       "            .selectAll(\".tokenAttention\")\n",
       "            .data(d => d)\n",
       "            .enter()\n",
       "            .append(\"g\")\n",
       "            .classed(\"tokenAttention\", true) // Group attention arcs by left token\n",
       "            .attr(\"left-token-index\", (d, i) => i)\n",
       "            .selectAll(\"line\")\n",
       "            .data(d => d)\n",
       "            .enter()\n",
       "            .append(\"line\")\n",
       "            .attr(\"x1\", BOXWIDTH)\n",
       "            .attr(\"y1\", function () {\n",
       "                const leftTokenIndex = +this.parentNode.getAttribute(\"left-token-index\")\n",
       "                return TEXT_TOP + leftTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2)\n",
       "            })\n",
       "            .attr(\"x2\", BOXWIDTH + MATRIX_WIDTH)\n",
       "            .attr(\"y2\", (d, rightTokenIndex) => TEXT_TOP + rightTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2))\n",
       "            .attr(\"stroke-width\", 2)\n",
       "            .attr(\"stroke\", function () {\n",
       "                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n",
       "                return headColors(headIndex)\n",
       "            })\n",
       "            .attr(\"left-token-index\", function () {\n",
       "                return +this.parentNode.getAttribute(\"left-token-index\")\n",
       "            })\n",
       "            .attr(\"right-token-index\", (d, i) => i)\n",
       "        ;\n",
       "        updateAttention(svg)\n",
       "    }\n",
       "\n",
       "    function updateAttention(svg) {\n",
       "        svg.select(\"#attention\")\n",
       "            .selectAll(\"line\")\n",
       "            .attr(\"stroke-opacity\", function (d) {\n",
       "                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n",
       "                // If head is selected\n",
       "                if (config.headVis[headIndex]) {\n",
       "                    // Set opacity to attention weight divided by number of active heads\n",
       "                    return d / activeHeads()\n",
       "                } else {\n",
       "                    return 0.0;\n",
       "                }\n",
       "            })\n",
       "    }\n",
       "\n",
       "    function boxOffsets(i) {\n",
       "        const numHeadsAbove = config.headVis.reduce(\n",
       "            function (acc, val, cur) {\n",
       "                return val && cur < i ? acc + 1 : acc;\n",
       "            }, 0);\n",
       "        return numHeadsAbove * (BOXWIDTH / activeHeads());\n",
       "    }\n",
       "\n",
       "    function activeHeads() {\n",
       "        return config.headVis.reduce(function (acc, val) {\n",
       "            return val ? acc + 1 : acc;\n",
       "        }, 0);\n",
       "    }\n",
       "\n",
       "    function drawCheckboxes(top, svg) {\n",
       "        const checkboxContainer = svg.append(\"g\");\n",
       "        const checkbox = checkboxContainer.selectAll(\"rect\")\n",
       "            .data(config.headVis)\n",
       "            .enter()\n",
       "            .append(\"rect\")\n",
       "            .attr(\"fill\", (d, i) => headColors(i))\n",
       "            .attr(\"x\", (d, i) => i * CHECKBOX_SIZE)\n",
       "            .attr(\"y\", top)\n",
       "            .attr(\"width\", CHECKBOX_SIZE)\n",
       "            .attr(\"height\", CHECKBOX_SIZE);\n",
       "\n",
       "        function updateCheckboxes() {\n",
       "            checkboxContainer.selectAll(\"rect\")\n",
       "                .data(config.headVis)\n",
       "                .attr(\"fill\", (d, i) => d ? headColors(i): lighten(headColors(i)));\n",
       "        }\n",
       "\n",
       "        updateCheckboxes();\n",
       "\n",
       "        checkbox.on(\"click\", function (d, i) {\n",
       "            if (config.headVis[i] && activeHeads() === 1) return;\n",
       "            config.headVis[i] = !config.headVis[i];\n",
       "            updateCheckboxes();\n",
       "            updateAttention(svg);\n",
       "        });\n",
       "\n",
       "        checkbox.on(\"dblclick\", function (d, i) {\n",
       "            // If we double click on the only active head then reset\n",
       "            if (config.headVis[i] && activeHeads() === 1) {\n",
       "                config.headVis = new Array(config.nHeads).fill(true);\n",
       "            } else {\n",
       "                config.headVis = new Array(config.nHeads).fill(false);\n",
       "                config.headVis[i] = true;\n",
       "            }\n",
       "            updateCheckboxes();\n",
       "            updateAttention(svg);\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function lighten(color) {\n",
       "        const c = d3.hsl(color);\n",
       "        const increment = (1 - c.l) * 0.6;\n",
       "        c.l += increment;\n",
       "        c.s -= increment;\n",
       "        return c;\n",
       "    }\n",
       "\n",
       "    function transpose(mat) {\n",
       "        return mat[0].map(function (col, i) {\n",
       "            return mat.map(function (row) {\n",
       "                return row[i];\n",
       "            });\n",
       "        });\n",
       "    }\n",
       "\n",
       "});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bertviz import head_view\n",
    "\n",
    "with open('self_attn_bertviz.json') as f:\n",
    "    data = json.load(f)\n",
    "attn_all = np.array(data['all'])  # (num_layers, num_heads, seq_len, seq_len)\n",
    "tokens = data['tokens']\n",
    "\n",
    "# ★ここを修正！\n",
    "attention = [torch.tensor(attn_all[i]).unsqueeze(0) for i in range(attn_all.shape[0])]\n",
    "\n",
    "print(f\"attn_all.shape: {attn_all.shape}, tokens: {tokens}\")\n",
    "head_view(attention=attention, tokens=tokens)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "generative_ai_disabled": true,
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
